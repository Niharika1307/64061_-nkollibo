{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "30FPfnFvP1gA",
        "outputId": "700f39f0-b3cf-45c8-953d-b23d366067ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a5aeb7e9-4a27-4661-bffa-cd984728804e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a5aeb7e9-4a27-4661-bffa-cd984728804e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"niharikakolliboyana\",\"key\":\"e8cf931b0dd5675e79dff657e4ad4e67\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle/"
      ],
      "metadata": {
        "id": "goT6mhtYP3-f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "bNwneky4P7bN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eeSCJcJ1QBx_",
        "outputId": "40f9813e-1f3d-4da4-98b5-e7334a548e34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            " 98% 799M/812M [00:03<00:00, 257MB/s]\n",
            "100% 812M/812M [00:03<00:00, 270MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq dogs-vs-cats.zip"
      ],
      "metadata": {
        "id": "22QdMqYrQEWg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq train.zip"
      ],
      "metadata": {
        "id": "n-8LTUGGQInU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Consider the Cats & Dogs example. Start initially with a training sample of 1000, a validation sample of 500, and a test sample of 500."
      ],
      "metadata": {
        "id": "3VlbI8Ukp1wM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copying images to training,validation and test set."
      ],
      "metadata": {
        "id": "Adx9VQvJjUmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_1\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1000)\n",
        "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
        "make_subset(\"test\", start_index=1500, end_index=2000)"
      ],
      "metadata": {
        "id": "TdO9pbWFQhCq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using convulational neural network."
      ],
      "metadata": {
        "id": "AWrB3ymtj2rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "VT4wuywDzCYt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fKMzDplnzGqT",
        "outputId": "19c8f36d-1f5c-4e64-825d-bfb35238d71a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 180, 180, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 178, 178, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 89, 89, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 87, 87, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 43, 43, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 41, 41, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 18, 18, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 9, 9, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 7, 256)         590080    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 12545     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 991,041\n",
            "Trainable params: 991,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "qSVlkcAJzKlG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be observed that,model might overfit,thus,we use regularization technique in the stage of DATA PREPROCESSING."
      ],
      "metadata": {
        "id": "M1-sS3uzkl0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here,all the images are converted to tensors."
      ],
      "metadata": {
        "id": "kZxekgoskz8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "m0SXDMmAzN6o",
        "outputId": "0a72fbc2-9a90-4ab5-a2ce-de62a5ef3266"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "callback can be used to save the model's weights after every epoch or to stop training early if the model is not improving. Additionally, callbacks can be used to log metrics, visualize the model's performance, or schedule learning rate changes."
      ],
      "metadata": {
        "id": "ZirGkq0QlRc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch1.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZDAW00mgzQpG",
        "outputId": "74d6b820-a53a-4f3f-e659-3d744aa31021"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "94/94 [==============================] - 21s 208ms/step - loss: 0.5810 - accuracy: 0.6990 - val_loss: 0.6046 - val_accuracy: 0.6800\n",
            "Epoch 2/10\n",
            "94/94 [==============================] - 18s 194ms/step - loss: 0.5731 - accuracy: 0.7073 - val_loss: 0.6312 - val_accuracy: 0.6800\n",
            "Epoch 3/10\n",
            "94/94 [==============================] - 19s 202ms/step - loss: 0.5594 - accuracy: 0.7160 - val_loss: 0.7043 - val_accuracy: 0.6600\n",
            "Epoch 4/10\n",
            "94/94 [==============================] - 19s 199ms/step - loss: 0.5641 - accuracy: 0.7073 - val_loss: 0.5755 - val_accuracy: 0.7000\n",
            "Epoch 5/10\n",
            "94/94 [==============================] - 19s 196ms/step - loss: 0.5415 - accuracy: 0.7190 - val_loss: 0.5638 - val_accuracy: 0.7110\n",
            "Epoch 6/10\n",
            "94/94 [==============================] - 19s 205ms/step - loss: 0.5238 - accuracy: 0.7410 - val_loss: 0.5417 - val_accuracy: 0.7150\n",
            "Epoch 7/10\n",
            "94/94 [==============================] - 19s 196ms/step - loss: 0.5195 - accuracy: 0.7533 - val_loss: 0.5610 - val_accuracy: 0.7100\n",
            "Epoch 8/10\n",
            "94/94 [==============================] - 19s 200ms/step - loss: 0.5022 - accuracy: 0.7483 - val_loss: 0.5172 - val_accuracy: 0.7460\n",
            "Epoch 9/10\n",
            "94/94 [==============================] - 19s 205ms/step - loss: 0.4960 - accuracy: 0.7530 - val_loss: 0.5899 - val_accuracy: 0.7040\n",
            "Epoch 10/10\n",
            "94/94 [==============================] - 18s 194ms/step - loss: 0.4777 - accuracy: 0.7747 - val_loss: 0.5957 - val_accuracy: 0.7120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it can be observed that accuracy is increasing with number of epochs.\n",
        "\n",
        "\n",
        "Accuracy=77.4%\n",
        "Val_acc=71.2%\n",
        "test_acc=76.1%"
      ],
      "metadata": {
        "id": "NDGOIu5Flk71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "TbQ4m94kzVg9",
        "outputId": "5c69040b-ffdb-4baf-969e-be0bdcf36183"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0uUlEQVR4nO3dd3hUZfbA8e8hNENvFgjVBVHEEIggYAHBFUVBUBFkVfSniIoFG+wiWBArK6CLuqCiAhrLKouKFCmruzYiYgEUKQGCigjSW8r5/fHehElImSST3MnM+TzPPJm59cxNcuad9773XFFVjDHGRK4KfgdgjDGmdFmiN8aYCGeJ3hhjIpwlemOMiXCW6I0xJsJZojfGmAhniT4KiciHInJNqJf1k4ikiEjPUtiuisifvOfPi8iYYJYtxn4Gi8iC4sZpTEHExtGXDyKyN+BlLHAIyPBe36iqs8o+qvAhIinA9ar6UYi3q0BLVV0bqmVFpBmwAaikqukhCdSYAlT0OwATHFWtnvW8oKQmIhUteZhwYX+P4cG6bso5EekmIqkiMlJEfgWmi0gdEXlfRLaJyB/e87iAdZaKyPXe8yEi8l8RmeAtu0FELijmss1F5GMR2SMiH4nIFBGZmU/cwcQ4TkT+521vgYjUD5h/lYhsFJHtIjK6gOPTSUR+FZGYgGn9RORb73lHEflMRHaKyC8i8g8RqZzPtl4WkYcDXt/jrfOziFyXa9neIvK1iOwWkc0i8kDA7I+9nztFZK+IdM46tgHrdxGRZSKyy/vZJdhjU8TjXFdEpnvv4Q8RmR0wr6+IrPDewzoR6eVNz9FNJiIPZP2eRaSZ14X1fyKyCVjsTX/L+z3s8v5G2gSsf4yI/N37fe7y/saOEZEPROTWXO/nWxHpl9d7NfmzRB8ZjgfqAk2Bobjf63TvdRPgAPCPAtbvBPwI1AeeAF4UESnGsq8BXwL1gAeAqwrYZzAxXglcCxwLVAbuBhCRU4DnvO039PYXRx5U9QtgH3Buru2+5j3PAEZ476cz0AO4uYC48WLo5cVzHtASyH1+YB9wNVAb6A3cJCKXePPO9n7WVtXqqvpZrm3XBT4Anvbe21PAByJSL9d7OOrY5KGw4zwD1xXYxtvWRC+GjsCrwD3eezgbSMlnH3k5BzgZON97/SHuOB0LLAcCuxonAB2ALri/43uBTOAV4C9ZC4lIPNAId2xMUaiqPcrZA/cP19N73g04DFQtYPl2wB8Br5fiun4AhgBrA+bFAgocX5RlcUkkHYgNmD8TmBnke8orxvsCXt8MzPOejwWSAuZV845Bz3y2/TDwkve8Bi4JN81n2TuAdwNeK/An7/nLwMPe85eAxwKWaxW4bB7bnQRM9J4385atGDB/CPBf7/lVwJe51v8MGFLYsSnKcQZOwCXUOnks98+seAv6+/NeP5D1ew54by0KiKG2t0wt3AfRASA+j+WqAn/gznuA+0B4tjT+pyL9YS36yLBNVQ9mvRCRWBH5p/dVeDeuq6B2YPdFLr9mPVHV/d7T6kVctiGwI2AawOb8Ag4yxl8Dnu8PiKlh4LZVdR+wPb994Vrv/UWkCtAfWK6qG704WnndGb96cTyCa90XJkcMwMZc76+TiCzxukx2AcOC3G7WtjfmmrYR15rNkt+xyaGQ49wY9zv7I49VGwPrgow3L9nHRkRiROQxr/tnN0e+GdT3HlXz2pf3N/0G8BcRqQAMwn0DMUVkiT4y5B46dRdwEtBJVWtypKsgv+6YUPgFqCsisQHTGhewfEli/CVw294+6+W3sKquwiXKC8jZbQOuC+gHXKuxJvC34sSA+0YT6DVgDtBYVWsBzwdst7Chbj/juloCNQG2BBFXbgUd582431ntPNbbDJyYzzb34b7NZTk+j2UC3+OVQF9c91YtXKs/K4bfgYMF7OsVYDCuS22/5urmMsGxRB+ZauC+Du/0+nvvL+0dei3kZOABEaksIp2Bi0spxreBi0TkTO/E6UMU/rf8GnA7LtG9lSuO3cBeEWkN3BRkDG8CQ0TkFO+DJnf8NXCt5YNef/eVAfO24bpMWuSz7blAKxG5UkQqisgVwCnA+0HGljuOPI+zqv6C6zt/1jtpW0lEsj4IXgSuFZEeIlJBRBp5xwdgBTDQWz4RuCyIGA7hvnXF4r41ZcWQiesGe0pEGnqt/87ety+8xJ4J/B1rzRebJfrINAk4Btda+hyYV0b7HYw7obkd1y/+Bu4fPC+TKGaMqroSuAWXvH/B9eOmFrLa67gThItV9feA6XfjkvAeYJoXczAxfOi9h8XAWu9noJuBh0RkD+6cwpsB6+4HxgP/Ezfa54xc294OXIRrjW/HnZy8KFfcwZpEwcf5KiAN963mN9w5ClT1S9zJ3onALuA/HPmWMQbXAv8DeJCc35Dy8iruG9UWYJUXR6C7ge+AZcAO4HFy5qZXgba4cz6mGOyCKVNqROQN4AdVLfVvFCZyicjVwFBVPdPvWMora9GbkBGR00XkRO+rfi9cv+xsn8My5ZjXLXYzMNXvWMozS/QmlI7HDf3bixsDfpOqfu1rRKbcEpHzcecztlJ495ApQFBdN17rbDIQA7ygqo/lmj8R6O69jAWOVdXa3rwncBeMVAAWArer9RcZY0yZKbTWjTfedgruCsBUYJmIzPGGrAGgqiMClr8VSPCedwG6Aqd5s/+LOyG2NETxG2OMKUQwRc064q6GXA8gIkm4vtdV+Sw/iCNDuBR3MURl3JjZSrivYfmqX7++NmvWLIiwjDHGZPnqq69+V9UGec0LJtE3IucVgKm4eidHEZGmQHO8oWaq+pmILMENgRPgH6q6Oo/1huJqtNCkSROSk5ODCMsYY0wWEcl9NXW2UJ+MHQi8raoZ3o7/hCtsFIf7wDhXRM7KvZKqTlXVRFVNbNAgzw8kY4wxxRRMot9Czku948j/UuyBuAtTsvQDPlfVvaq6F3cVXufiBGqMMaZ4gkn0y4CW4mqNV8Yl8zm5F/Iuj66Dq7KXZRNwjncZdyXcidijum6MMcaUnkL76FU1XUSGA/NxwytfUtWVIvIQkKyqWUl/IK50bODQybdxdcC/w52Ynaeq7xU1yLS0NFJTUzl48GDhC5uoULVqVeLi4qhUqZLfoRgT9sKuBEJiYqLmPhm7YcMGatSoQb169cj/fhgmWqgq27dvZ8+ePTRv3tzvcIwJCyLylaom5jWvXFwZe/DgQUvyJpuIUK9ePfuGZyLGrFnQrBlUqOB+zppV2BpFU25uDm5J3gSyvwcTKWbNgqFDYb93y56NG91rgMGDQ7OPctGiN8aYSDV69JEkn2X/fjc9VCzRB2H79u20a9eOdu3acfzxx9OoUaPs14cPHy5w3eTkZG677bZC99GlS5dQhWuMKUc2bSra9OKIyEQf6v6uevXqsWLFClasWMGwYcMYMWJE9uvKlSuTnp6e77qJiYk8/fTThe7j008/LVmQPsjIyPA7BGPKvSa5b0JZyPTiiLhEn9XftXEjqB7p7wr1yY0hQ4YwbNgwOnXqxL333suXX35J586dSUhIoEuXLvz4448ALF26lIsuugiABx54gOuuu45u3brRokWLHB8A1atXz16+W7duXHbZZbRu3ZrBgweTNTJq7ty5tG7dmg4dOnDbbbdlbzdQSkoKZ511Fu3bt6d9+/Y5PkAef/xx2rZtS3x8PKNGjQJg7dq19OzZk/j4eNq3b8+6detyxAwwfPhwXn75ZQCaNWvGyJEjad++PW+99RbTpk3j9NNPJz4+nksvvZT93nfQrVu30q9fP+Lj44mPj+fTTz9l7NixTJo0KXu7o0ePZvLkySX9VRhTro0fD7GxOafFxrrpIaOqYfXo0KGD5rZq1aqjpuWnaVNVl+JzPpo2DXoTBbr//vv1ySef1GuuuUZ79+6t6enpqqq6a9cuTUtLU1XVhQsXav/+/VVVdcmSJdq7d+/sdTt37qwHDx7Ubdu2ad26dfXw4cOqqlqtWrXs5WvWrKmbN2/WjIwMPeOMM/STTz7RAwcOaFxcnK5fv15VVQcOHJi93UD79u3TAwcOqKrqmjVrNOt4zp07Vzt37qz79u1TVdXt27erqmrHjh31nXfeUVXVAwcO6L59+3LErKp6yy236PTp01VVtWnTpvr4449nz/v999+zn48ePVqffvppVVUdMGCATpw4UVVV09PTdefOnbphwwZNSEhQVdWMjAxt0aJFjvWLqih/F8aEs5kzXY4ScT9nziz6NnDXNeWZV8vNqJtglUV/V5bLL7+cmJgYAHbt2sU111zDTz/9hIiQlpaW5zq9e/emSpUqVKlShWOPPZatW7cSFxeXY5mOHTtmT2vXrh0pKSlUr16dFi1aZI8bHzRoEFOnHn3TnbS0NIYPH86KFSuIiYlhzZo1AHz00Udce+21xHpNh7p167Jnzx62bNlCv379AHcRUjCuuOKK7Offf/899913Hzt37mTv3r2cf/75ACxevJhXX30VgJiYGGrVqkWtWrWoV68eX3/9NVu3biUhIYF69eoFtU9jItngwaEbYZOXiEv0TZq47pq8podatWrVsp+PGTOG7t278+6775KSkkK3bt3yXKdKlSrZz2NiYvLs3w9mmfxMnDiR4447jm+++YbMzMygk3egihUrkpmZmf0693j1wPc9ZMgQZs+eTXx8PC+//DJLly4tcNvXX389L7/8Mr/++ivXXXddkWMzxhRdxPXRl0l/Vx527dpFo0aNALL7s0PppJNOYv369aSkpADwxhtv5BvHCSecQIUKFZgxY0b2CdPzzjuP6dOnZ/eh79ixgxo1ahAXF8fs2bMBOHToEPv376dp06asWrWKQ4cOsXPnThYtWpRvXHv27OGEE04gLS2NWQEnQnr06MFzzz0HuJO2u3btAqBfv37MmzePZcuWZbf+jTGlK+IS/eDBMHUqNG0KIu7n1Kml+7UI4N577+Wvf/0rCQkJRWqBB+uYY47h2WefpVevXnTo0IEaNWpQq1ato5a7+eabeeWVV4iPj+eHH37Ibn336tWLPn36kJiYSLt27ZgwYQIAM2bM4Omnn+a0006jS5cu/PrrrzRu3JgBAwZw6qmnMmDAABISEvKNa9y4cXTq1ImuXbvSunXr7OmTJ09myZIltG3blg4dOrBqlbtPTeXKlenevTsDBgzI7vYyxpSuclHrZvXq1Zx88sk+RRQ+9u7dS/Xq1VFVbrnlFlq2bMmIESMKXzGMZGZmZo/YadmyZYm2ZX8XxhxR7mvdGGfatGm0a9eONm3asGvXLm688Ua/QyqSVatW8ac//YkePXqUOMkbY4IXcSdjI9mIESPKXQs+0CmnnML69ev9DsOYqGMtemOMiXCW6I0xJsJZojfGmAhnid4YYyKcJfogdO/enfnz5+eYNmnSJG666aZ81+nWrRtZw0QvvPBCdu7cedQyDzzwQPZ49vzMnj07eww6wNixY/noo4+KEL0xJtpZog/CoEGDSEpKyjEtKSmJQYMGBbX+3LlzqV27drH2nTvRP/TQQ/Ts2bNY2/KLlTM2xl+W6INw2WWX8cEHH2TfZCQlJYWff/6Zs846i5tuuonExETatGnD/fffn+f6zZo14/fffwdg/PjxtGrVijPPPDO7lDGQZ7nfTz/9lDlz5nDPPffQrl071q1bx5AhQ3j77bcBWLRoEQkJCbRt25brrruOQ4cOZe/v/vvvp3379rRt25YffvjhqJisnLEx0aPcjaO/4w5YsSK022zXDgLyylHq1q1Lx44d+fDDD+nbty9JSUkMGDAAEWH8+PHUrVuXjIwMevTowbfffstpp52W53a++uorkpKSWLFiBenp6bRv354OHToA0L9/f2644QYA7rvvPl588UVuvfVW+vTpw0UXXcRll12WY1sHDx5kyJAhLFq0iFatWnH11Vfz3HPPcccddwBQv359li9fzrPPPsuECRN44YUXcqx/7LHHsnDhQqpWrcpPP/3EoEGDSE5O5sMPP+Tf//43X3zxBbGxsezYsQOAwYMHM2rUKPr168fBgwfJzMxk8+bNBR7XevXqsXz5csDdpSuv93fbbbdxzjnn8O6775KRkcHevXtp2LAh/fv354477iAzM5OkpCS+/PLLAvdljMmfteiDFNh9E9ht8+abb9K+fXsSEhJYuXJljm6W3D755BP69etHbGwsNWvWpE+fPtnzvv/+e8466yzatm3LrFmzWLlyZYHx/PjjjzRv3pxWrVoBcM011/Dxxx9nz+/fvz8AHTp0yC6EFigtLY0bbriBtm3bcvnll2fHHWw549jclePykLuccV7vb/HixdnnOrLKGTdr1iy7nPGCBQusnLExJVTuWvQFtbxLU9++fRkxYgTLly9n//79dOjQgQ0bNjBhwgSWLVtGnTp1GDJkyFElfYNV1HK/hckqdZxfmWMrZ2xM9LAWfZCqV69O9+7due6667Jb87t376ZatWrUqlWLrVu38uGHHxa4jbPPPpvZs2dz4MAB9uzZw3vvvZc9L79yvzVq1GDPnj1Hbeukk04iJSWFtWvXAq4K5TnnnBP0+7FyxsZEj6ASvYj0EpEfRWStiIzKY/5EEVnhPdaIyM6AeU1EZIGIrBaRVSLSLHThl61BgwbxzTffZCf6+Ph4EhISaN26NVdeeSVdu3YtcP327dtzxRVXEB8fzwUXXMDpp5+ePS+/cr8DBw7kySefJCEhgXXr1mVPr1q1KtOnT+fyyy+nbdu2VKhQgWHDhgX9XqycsTHRo9AyxSISA6wBzgNSgWXAIFXNszNaRG4FElT1Ou/1UmC8qi4UkepApqruz29/VqbYQHDljO3vwpgjSlqmuCOwVlXXq+phIAnoW8Dyg4DXvR2fAlRU1YUAqrq3oCRvDFg5Y2NCLZiTsY2AwHF0qUCnvBYUkaZAc2CxN6kVsFNE3vGmfwSMUlW7gsbky8oZGxNaoT4ZOxB4OyCRVwTOAu4GTgdaAENyryQiQ0UkWUSSt23blueGw+1OWMZf9vdgTPCCSfRbgMYBr+O8aXkZiNdt40kFVnjdPunAbKB97pVUdaqqJqpqYoMGDY7aaNWqVdm+fbv9cxvAJfnt27cXa0ioMdEomK6bZUBLEWmOS/ADgStzLyQirYE6wGe51q0tIg1UdRtwLpCce93CxMXFkZqaSn6tfRN9qlatSlxcnN9hGFMuFJroVTVdRIYD84EY4CVVXSkiDwHJqjrHW3QgkKQBzW5VzRCRu4FFIiLAV8C0ogZZqVIlmjdvXtTVjDHGEMTwyrKW1/BKY4wxBSvp8EpjjDHlmCV6Y4yJcJbojTEmwlmiNybKzJoFzZpBhQruZ0CNOROhLNEbE0VmzYKhQ2HjRlB1P4cOjd5kHy0fepbojYkio0fD/lzVpvbvd9OjTTR96FmiNyaKbNpUtOmRLJo+9CzRGxNFmjQp2vRIFk0fepbojYki48dD7tv9xsa66dEmmj70LNEbE0UGD4apU6FpUxBxP6dOddOjTTR96JW7m4MbY0pm8ODoTOy5ZR2D0aNdd02TJi7JR+KxsURvjIla0fKhZ103xpgyFy3j18OFteiNMWUqa/x61tDGrPHrEB2taz9Yi94YU6aiafx6uLBEb4wpU9E0fj1cWKI3xpSpaBq/Hi4s0RtjylQ0jV8PF5bojTFlKuuirfr13euGDaP3oq2yYoneGFPm+veHY45xz3v1siRf2izRG2PK3DPPwObN0KULzJgBqal+RxTZLNEbY8rU9u3wyCPQuzfMnAmZmTBpkt9RRTZL9MaYMvXII7BnDzz2GDRvDldcAf/8J/zxh9+RRS5L9MaYMpOSAv/4BwwZAqee6qaNHAl798Kzz/oZWWSzRG9MGbH6LnDffRATAw8+eGTaaafBhRfC5Mlw4IB/sUUyS/TGlIFouj9pfpYvd+/3jjsgLi7nvJEjYds2mD7dl9Ainqhq4QuJ9AImAzHAC6r6WK75E4Hu3stY4FhVrR0wvyawCpitqsML2ldiYqImJycX5T0YE/aaNXPJPbemTV13RqRThfPOgxUrYN06qFXr6Pldu8Ivv8BPP0FFK7dYZCLylaom5jWv0Ba9iMQAU4ALgFOAQSJySuAyqjpCVdupajvgGeCdXJsZB3xcjNiNiQjRXt9lwQJYtAjGjDk6yYO729XIke5D7803yzy8iBdM101HYK2qrlfVw0AS0LeA5QcBr2e9EJEOwHHAgpIEakx5Fs31XTIyXBJv0QJuuin/5S6+GE4+GR5/3LXwTegEk+gbAZsDXqd6044iIk2B5sBi73UF4O/A3QXtQESGikiyiCRv27YtmLiNKVeiub7LrFnwzTfuvVaunP9yFSq4D4Rvv4V588ouvmgQ6pOxA4G3VTXDe30zMFdVC7zuTVWnqmqiqiY2aNAgxCEZ479ovSn3wYNupE1iIgwYUPjygwa5E7WPP176sUWTYE55bAEaB7yO86blZSBwS8DrzsBZInIzUB2oLCJ7VXVUcYI1pjyLlvuTBsoqdfDKK67FXpjKleGuu2DECPj8czjjjNKPMRoUOupGRCoCa4AeuAS/DLhSVVfmWq41MA9ornlsVESGAIk26saY6LBjB5x4oqtn88EHwa+3d687d3HOOfDuu6UXX6Qp0agbVU0HhgPzgdXAm6q6UkQeEpE+AYsOBJLySvLGmOjzyCOwa5crdVAU1avDrbfC7NmwenWphBZ1ghpHX5asRW9M+ZeSAied5LqqXnqp6Ov//rtr1V9xhV1EFawSteiNMaaoxoxxffIPPVS89evXh+uvdyN2Nm8ufHlTMEv0xpiQ+vrr/EsdFMVdd7kSxhMnhiy0qGWJ3hgTUiNHQp067mdJNG3qhltOnepO7Jris0RvjAmZBQtg4ULXdVO7dsm3d++9sG8fTJlS8m1FM0v0xpiQyMx0rfhmzQoudVAUbdu6O1E9/TTs3x+abUYjS/TGmJB47TVXnfKRR6BKldBtd9QoNwqnOKN3jGPDK40xJXbwoBtO2aABfPllcFfBFkXXrrBliythXKlSaLcdKWx4pTGmVE2Z4kouP/FE6JM8uFb9xo1Wwri4rEVvjCmRP/5wpQ46dYIPPyydfWRmulsOVqjgKmGKlM5+yjNr0RtjSs2jj8LOnaVbcbJCBTcC57vvSu/DJJJZojfGFNumTW5EzNVXuxZ3aRo0CBo3LnrtHGOJ3hhTAmPGuJ/jxpX+vipVclfLfvIJfPpp6e8vkliiN8YUyzffwIwZcPvtrqVdFq6/HurWtRuTFJUlemNMsWSVOvjrX8tun9WquRLGc+bAqlVlt9/yzhK9MabIPvoI5s+H0aNDU+qgKIYPd/fbfeKJst1veWaJ3hhTJJmZbgRMs2Zwyy2FLh5y9evDDTe4CpmbNpX9/ssjS/TGmCJ5/XVXivjhh0Nb6qAo7rzT/bQSxsGxRG+MCdqhQ667JiHBDXf0S5MmcOWVroTx9u3+xVFeWKI3xgRtyhRXiqC0Sh0Uxb33uoqWVsK4cJbojTFB+eMP111z/vnQs6ff0UCbNnDxxe6CrX37/I4mvFmiN8YE5bHHSr/UQVGNGuW6bqyEccEs0RtjCrVpE0yeDFddBfHxfkdzRJcucOaZMGECpKX5HU34skRvjCnU2LHuZ1mUOiiqUaPcB1FSkt+RhC9L9MaYAn37Lbz6Ktx2mxvtEm4uvBBOPdV1KWVm+h1NeLJEb4wp0MiR7urXsix1UBQiLsaVK2HuXL+jCU9BJXoR6SUiP4rIWhEZlcf8iSKywnusEZGd3vR2IvKZiKwUkW9F5IoQx2+MKUWLFsG8eW7sfJ06fkeTvyuucN82wulEcTgpNNGLSAwwBbgAOAUYJCKnBC6jqiNUtZ2qtgOeAd7xZu0HrlbVNkAvYJKI1A5d+MaY0pJV6qBJE39KHRRFpUpw993w3//C//7ndzThJ5gWfUdgraquV9XDQBLQt4DlBwGvA6jqGlX9yXv+M/Ab0KBkIRtTNLNmubosFSq4n7Nm+R1R+fDGG7B8OYwfD1Wr+h1N4f7v/1wdHGvVHy2YRN8I2BzwOtWbdhQRaQo0BxbnMa8jUBlYl8e8oSKSLCLJ27ZtCyZuY4IyaxYMHequ5lR1P4cOtWRfmEOH4G9/g3btXKmB8iA21pUwfu89+P57v6MJL6E+GTsQeFtVMwInisgJwAzgWlU96ry4qk5V1URVTWzQwBr8JnRGj3aXyQfav99NN/l77jlISQmPUgdFccstrma9lTDOKZhf4RYg8P4xcd60vAzE67bJIiI1gQ+A0ar6eXGCNKa48itja+Vt87dzpxsvf9557lGe1KvnShi//rr79macYBL9MqCliDQXkcq4ZD4n90Ii0hqoA3wWMK0y8C7wqqq+HZqQjQlefuO+w3E8eLh4/HFX16a89nVnlTB+6il/4wgnhSZ6VU0HhgPzgdXAm6q6UkQeEpE+AYsOBJJUVQOmDQDOBoYEDL9sF7rwTV7s5OMR48e7vttAsbFuujna5s0waRIMHuxKEZdHjRu7+F94AX7/3e9owoSqhtWjQ4cOaopv5kzV2FhVd+rRPWJj3fRoNXOmatOmqiLuZzQfi8Jce61q5cqqKSl+R1IyK1e6v/377/c7krIDJGs+eVU0RwPcf4mJiZqcnOx3GOVWs2Z59002bepOrhmTn+++cwXL7roLnnzS72hK7pJL4JNP3PmYatX8jqb0ichXqpqY17xydD7dBMNOPpriGjUKatUK31IHRTVyJOzY4bpwol1FvwMwodWkSd4tejv56J9Dh1xhsORkWLEC4uLg3HPh9NOhcmW/o3OWLHF1Yp58EurW9Tua0OjcGc4+G/7+d7j5Znf1bLSyrpsIk3WBUODY8dhYd2/NwYP9iytapKW54lrJyUce3357pFZ6rVqwe7c7exIb62qpn3sudO8O7dtDRR+aXpmZ0KkT/PYb/Phj+bgKNlhz50Lv3vDKK3D11X5HU7oK6rqxRB+BZs1yFwRt2uRa8uPHW5IvDRkZ8MMPOZP6ihVw8KCbX6sWJCYeeZx+uvt97NgB//mPa0UvWeI+GABq1oSzznJJ/9xzXX95WVyslJTkbvT96qvuxiKRRNUdx4wMdw6iPF38VVSW6I0pocxMWLs2Z1JfvvzIvUqrVYMOHXIm9RYtgkssW7fC0qVHEv+aNW56nTpwzjlHWvxt2riSvKF06BCcfLL7kFm+PDIT4axZ8Je/wJw57h6zkcoSvTFFoOpGKAUm9a++gl273PyqVd0Y88Ck3qoVxMSEZv9bthxJ+kuWwIYNbnqDBtCt25HE36pVyRP/5Mlwxx0wfz78+c8ljTw8padDy5bQsGFkV7a0RG9MPlRdYg1M6snJ7obT4E7gxcfn7IJp06Zs+9JTUnIm/tRUN/2EE45083TvDs2bFy3x79oFJ57oPrQWLiyV0MPGlCkwfLgbbnnmmX5Hc7S0NFeMbc8euOaa4m3DEr0xnq1bj07qv/7q5sXEuFvSBSb1tm2hShV/Yw6k6rqQAhP/1q1uXpMmORN/48YFb+tvf4NHH3VdNuX1Kthg7d/vriXp1Anef9/vaI7YvBmmTXNDQH/5xX07/OKL4n1Ts0RvotrPP8ODD7oRGFmtYRHXNx2Y1OPjjy6XEO5UYfXqnIl/xw4378QTcyb+448/sl5qquvOuPRSmDnTn9jL2sMPw5gxbhRU27b+xZGZ6brKnn/efeiouvveDhsGF1xQ/C5AS/QmKu3bBxMmuJK1aWnQr59r0SUmuhZsjRp+Rxh6mZludElW0v/Pf46cW2jd+kjinz0b3nrLDads1szPiMvOjh3uW0+/fjBjRtnv/7ff4KWX3FDnDRvg2GPh+utdtc1Q/A4KSvS+17bJ/bBaN6akMjJUp09XbdjQ1Tu57DLVtWv9jsof6emqy5apPvGE6gUXqFardqQG0p13+h1d2bvzTtWYGNUNG8pmf5mZqkuXqg4cqFqpkjvu3burvvGG6qFDod0XVuvGRIvFi12tlhUroGNHV6q2a1e/owofaWlHxvtfdRVUr+53RGUrNdUNex02DJ5+uvT2s3Onuy7h+edd11rt2jBkCNx4o/tmVRqs1k0ZsfLAOZXl8fjxR+jbF3r0cF/RX3sNPvvMknxulSq50gA33RR9SR5c+Ym//MWd/CyNu5YuW+buXduwIdx+u7s+Yfp0N7Jr4sTSS/KFyq+p79ejvHbdWHngnMrqeGzbpnrrraoVK6rWqKH66KOq+/eHdh8msqxa5UpWjx0bmu3t3as6bZpqhw7u77xaNdWhQ1WXLw/N9oNFAV03vif23I/ymuibNs2Z1LIeTZv6HZk/Svt4HDyo+uSTqrVqqVaooDpsmOrWraHZtol8l1yiWqeO6p49xd/G99+rDh+uWrOm+9s+9VTVKVNUd+0KXZxFUVCit66bELHywDmV1vFQhbffdkMj77kHunRxw+Wee86NYjAmGCNHutslTptWtPUOHXLdgmef7a65mDoV+vSB//7X/R3efLPrrgk3luhDxO5NmlNpHI8vvnBFvy6/3NWWmT/fjY1v06b42zTR6YwzXB2hp56Cw4cLX37dOvfhEBfnCgT+/LMr6bxlixuq2bVr6OsQhZIl+hCxe5PmFMrjsXEjXHml++dcu9a1olasiNzaLKZsjBrlRuG89lre89PT3fUGvXrBn/7k6tqffTYsWOAKz919N9SvX6YhF19+fTp+PcprH72q3Zs0t5Iej127VEeNUq1SRbVqVdXRo1V37y6NSE00ysxUjY9XPflkd+1FltRU1QceUG3UyPW9N2qk+uCDqlu2+BZqULBx9KY8SU+HF190l6tv2+aGwz3ySOG1W4wpqtdfd98W333XfeN8/nlXzjgzE84/3423793bnxvCFFVB4+jLQfgmmsyb5y54WrXK9cfPnetKFhhTGi6/3N2k59JLXXJv0MB1yQwd6i6sihSW6E1Y+O479w+2YIErxvXOO3DJJeF9gsuUfxUruhOy06a5b479+4dXtdJQsURvfPXrrzB2rOuqqVXLXT14883hc9NsE/kuucQ9IpkleuOLAwdcS+qxx9w9Vm+7zfXJ163rd2TGRB5L9KZMZWa64Wx/+5u76UK/fvD44642ujGmdAQ1jl5EeonIjyKyVkRG5TF/oois8B5rRGRnwLxrROQn71HMm2SZSPDJJ64e/FVXuatYly51ffGW5I0pXYW26EUkBpgCnAekAstEZI6qrspaRlVHBCx/K5DgPa8L3A8kAgp85a37R0jfhQlra9e6qwrfecddWfjqq+7qwgp2uZ4xZSKYf7WOwFpVXa+qh4EkoG8Byw8CXveenw8sVNUdXnJfCPQqScD5sRLB4enFF+GUU1y5gnHjXDnhq66yJG9MWQqmj74RsDngdSrQKa8FRaQp0BxYXMC6jfJYbygwFKBJMYqhzJrlxr3u3+9eb9zoXoNrORp/7N7tCo+dcQa88QaccILfERkTnULdrhoIvK2qGUVZSVWnqmqiqiY2aNCgyDsdPfpIks+yf7+bbvwzZYqrEPjUU5bkjfFTMIl+CxB48XmcNy0vAznSbVPUdYvNSgSHn717XYK/4AK7stUYvwWT6JcBLUWkuYhUxiXzObkXEpHWQB3gs4DJ84E/i0gdEakD/NmbFlJWIjj8PP88/P67GxtvjPFXoYleVdOB4bgEvRp4U1VXishDItInYNGBQJIGVElT1R3AONyHxTLgIW9aSFmJ4PCyfz9MmAA9e7r7kxpj/BXUBVOqOheYm2va2FyvH8hn3ZeAl4oZX1CyTriOHu26a5o0cUneTsT6Y9o02LoV3nrL70iMMYCVKTahdfCgK0rWqhUsWeJ3NMZEDytTbMrMSy+526zNmOF3JMaYLHbZigmZw4ddkbKuXaF7d7+jMcZksRa9CZlXXnGFyqZNszryxoQTa9GbkEhLc7f769jRbtptTLixFr0JiVmzICUFnnnGWvPGhBtr0ZsSS093w1kTEtyNlI0x4cVa9KbE3njDlSJ+5x1rzRsTjqxFb0okIwMefhjatoW+BRWvNsb4xlr0pkT+9S/44Qd4802rMW9MuLJ/TVNsmZnuZiInnwyXXup3NMaY/FiL3hTbv/8N33/vRtxYa96Y8GX/nqZYVOGhh9yNva+4wu9ojDEFsRa9KZb334cVK+DllyEmxu9ojDEFsRa9KTJV1zffvDlceaXf0RhjCmMtelNk8+fDsmWupk2lSn5HY4wpjLXoTZFk9c03aQJXX+13NMaYYFiL3hTJ4sXw2Wfw7LNQubLf0RhjgmEtelMk48ZBw4Zw7bV+R2KMCZa16E3QPv4Y/vMfmDwZqlb1OxpjTLCsRW+CNm4cHHcc3HCD35EYY4rCWvQmKJ9+Ch99BBMmwDHH+B2NMaYorEVvgjJuHNSvD8OG+R2JMaaoLNGbQi1bBvPmwV13QbVqfkdjjCkqS/SmUOPGQd26cMstfkdijCmOoBK9iPQSkR9FZK2IjMpnmQEiskpEVorIawHTn/CmrRaRp0XsHkTlyddfw3vvwR13QI0afkdjjCmOQk/GikgMMAU4D0gFlonIHFVdFbBMS+CvQFdV/UNEjvWmdwG6Aqd5i/4XOAdYGso3YUrPww9DrVpw661+R2KMKa5gRt10BNaq6noAEUkC+gKrApa5AZiiqn8AqOpv3nQFqgKVAQEqAVtDE3pOhw7Bhx+WxpaLrmZN6Nat/Ndo//57dx/YMWOgdm2/ozHGFFcwib4RsDngdSrQKdcyrQBE5H9ADPCAqs5T1c9EZAnwCy7R/0NVV+fegYgMBYYCNGnSpMhvAmD3bujXr1irloobb4TnnivfN8t++GGoXt112xhjyq9QjaOvCLQEugFxwMci0haoD5zsTQNYKCJnqeongSur6lRgKkBiYqIWJ4A6dVx/cjh47TV48kmoWBGeeaZ8Jvus+8COHOlOxBpjyq9gEv0WoHHA6zhvWqBU4AtVTQM2iMgajiT+z1V1L4CIfAh0Bj4hxCpWhHbtQr3V4omPd1UeJ0xwZXyfeqr8Jfvx492FUXfe6XckxpiSCqYXeRnQUkSai0hlYCAwJ9cys3FJHRGpj+vKWQ9sAs4RkYoiUgl3IvaorptIIwJPPAG33w6TJsG997rEX1789JP7VnLzzdCggd/RGGNKqtAWvaqmi8hwYD6u//0lVV0pIg8Byao6x5v3ZxFZBWQA96jqdhF5GzgX+A53Ynaeqr5XWm8mnIjAxImQnn6kZT9+fPlo2T/6qCtBfNddfkdijAmFoProVXUuMDfXtLEBzxW403sELpMB3FjyMMsnEXj6aUhLc8mzUiV48EG/oyrYhg3w6qswfDgcf7zf0RhjQsGKmpWyChXc6Jv0dHdnpkqV4L77/I4qf4895m72fc89fkdijAkVS/RloEIFmDrVtezHjHHJfuRIv6M62qZNMH26K0PcqJHf0RhjQsUSfRmJiXFJND0dRo1yyT7cRrQ88YT7GY4fQsaY4rNEX4ZiYlz/d3q6O9FZsSLcdpvfUTk//wwvvABDhrgbfxtjIocl+jJWsSLMmuWS/e23u5b9TTf5HZW7wCvr24YxJrKU82os5VOlSpCUBBdf7MaqT5vmbzxbt8Lzz8NVV0GLFv7GYowJPUv0PqlcGd56Cy680NXFefll/2L5+9/h8GH429/8i8EYU3os0fuoShX417/gvPPguutg5syyj2HbNpgyBQYNgpYty37/xpjSZ4neZ1WrwuzZ0L07XHMNvP562e5/4kQ4cABGjy7b/Rpjyo4l+jBwzDEwZw6ceabrJ3/rrbLZ744d8I9/wOWXw8knl80+jTFlzxJ9mKhWDT74AM44A6680rXyS9vkybBnT3hfqWuMKTlL9GGkenWYOxcSE2HAAHj//dLb165dLtH36wdt25befowx/rNEH2Zq1oR581xN+0svdc9LwzPPuGQ/ZkzpbN8YEz4s0YehWrVgwQJo0wYuuQQWLgzt9vfscSdhL7oIEhJCu21jTPixRB+m6tRxCf6kk6BPH1iyJHTbfvZZdyLWWvPGRAdL9GGsXj346CM48UTX+v7445Jvc98+d4HU+edDx44l354xJvxZog9zDRrAokWu0NiFF8L//ley7f3zn+4iqbFjC1/WGBMZLNGXA8cdB4sXuxrxF1wAn39evO0cOOBKEffoAV26hDZGY0z4skRfTpxwgkv2xx7rul2Sk4u+jRdecAXMrG/emOhiib4cadTIJfu6dV19nK+/Dn7dQ4fg8cfh7LPhnHNKL0ZjTPixRF/ONGniRuDUrAk9e8K33wa33vTpsGWLteaNiUaW6MuhZs1cy/6YY1x/+8qVBS9/+DA8+ih07uyWN8ZEF0v05dSJJ7qWfaVKLnn/8EP+y86Y4W78PWYMiJRdjMaY8GCJvhxr2dK17AHOPRd++unoZdLT4ZFHXP2cXr3KNj5jTHiwRF/OtW7txtmnp7ua9uvW5Zz/2muwfr215o2JZpboI0CbNu4K2gMHXMs+JcVNz8iA8eNdgbSLL/Y1RGOMj4JK9CLSS0R+FJG1IjIqn2UGiMgqEVkpIq8FTG8iIgtEZLU3v1mIYjcBTjvNJfvdu13LftMmePNNWLPGXQVrrXljopeoasELiMQAa4DzgFRgGTBIVVcFLNMSeBM4V1X/EJFjVfU3b95SYLyqLhSR6kCmqu7Pb3+JiYmaXJyrgQzgLqTq2dPVyalY0d2E/JtvoIJ9dzMmoonIV6qamNe8ikGs3xFYq6rrvY0lAX2BVQHL3ABMUdU/AAKS/ClARVVd6E3fW+x3YYKSmAjz57sLqvbsgaQkS/LGRLtgUkAjYHPA61RvWqBWQCsR+Z+IfC4ivQKm7xSRd0TkaxF50vuGkIOIDBWRZBFJ3rZtW3HehwnQqZM7QTt2LFx2md/RGGP8FkyLPtjttAS6AXHAxyLS1pt+FpAAbALeAIYALwaurKpTgangum5CFFNUO/109zDGmGBa9FuAxgGv47xpgVKBOaqapqobcH36Lb3pK1R1vaqmA7OB9iWO2hhjTNCCSfTLgJYi0lxEKgMDgTm5lpmNa80jIvVxXTbrvXVri0gDb7lzydm3b4wxppQVmui9lvhwYD6wGnhTVVeKyEMi0sdbbD6wXURWAUuAe1R1u6pmAHcDi0TkO0CAaaXxRowxxuSt0OGVZc2GVxpjTNEVNLzSBt4ZY0yEs0RvjDERzhK9McZEOEv0xhgT4cLuZKyIbAM2+h1HCdUHfvc7iDBixyMnOx5H2LHIqSTHo6mqNshrRtgl+kggIsn5nf2ORnY8crLjcYQdi5xK63hY140xxkQ4S/TGGBPhLNGXjql+BxBm7HjkZMfjCDsWOZXK8bA+emOMiXDWojfGmAhnid4YYyKcJfoQEpHGIrIk4Cbpt/sdk99EJMa7u9j7fsfiNxGpLSJvi8gPIrJaRDr7HZOfRGSE93/yvYi8LiJV/Y6pLInISyLym4h8HzCtrogsFJGfvJ91QrEvS/ShlQ7cpaqnAGcAt3j3zY1mt+PKWxuYDMxT1dZAPFF8XESkEXAbkKiqpwIxuHtdRJOXgV65po0CFqlqS2CR97rELNGHkKr+oqrLved7cP/Iue+vGzVEJA7oDbzgdyx+E5FawNl4t9FU1cOqutPXoPxXEThGRCoCscDPPsdTplT1Y2BHrsl9gVe8568Al4RiX5boS4mINMPdK/cLn0Px0yTgXiDT5zjCQXNgGzDd68p6QUSq+R2UX1R1CzABdy/pX4BdqrrA36jCwnGq+ov3/FfguFBs1BJ9KRCR6sC/gDtUdbff8fhBRC4CflPVr/yOJUxUxN0v+TlVTQD2EaKv5eWR1/fcF/cB2BCoJiJ/8Teq8KJu7HtIxr9bog8xEamES/KzVPUdv+PxUVegj4ikAEnAuSIy09+QfJUKpKpq1je8t3GJP1r1BDao6jZVTQPeAbr4HFM42CoiJwB4P38LxUYt0YeQiAiuD3a1qj7ldzx+UtW/qmqcqjbDnWRbrKpR22JT1V+BzSJykjepB7DKx5D8tgk4Q0Rivf+bHkTxyekAc4BrvOfXAP8OxUYt0YdWV+AqXOt1hfe40O+gTNi4FZglIt8C7YBH/A3HP943m7eB5cB3uFwUVeUQROR14DPgJBFJFZH/Ax4DzhORn3Dfeh4Lyb6sBIIxxkQ2a9EbY0yEs0RvjDERzhK9McZEOEv0xhgT4SzRG2NMhLNEb4wxEc4SvTHGRLj/B4tS08ninumGAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxI0lEQVR4nO3dd3iUVfbA8e+hG5oIiEjXpYh0AqisCBYEYUAUFUQh6yKCuir6k0URQRR1Vx5lVSxYEBVFF1cWBERUENZKFQFpUjSAEoJ0kHZ+f9wJTELKJJmZd8r5PM88mXnnLWcmyZk7973vuaKqGGOMiV9FvA7AGGNMeFmiN8aYOGeJ3hhj4pwlemOMiXOW6I0xJs5ZojfGmDhnid7ki4jMEpF+oV7XSyKySUQuD8N+VUT+5L//kogMD2bdAhynj4h8UtA4c9lvexFJDfV+TeQV8zoAE34isi/gYRLwB3DM//g2VZ0U7L5UtXM41o13qjowFPsRkdrARqC4qh7173sSEPTv0CQeS/QJQFXLZNwXkU1Af1X9NOt6IlIsI3kYY+KHdd0ksIyv5iLydxH5FZggIhVE5CMRSROR3/33qwdsM09E+vvvp4jI/0RkjH/djSLSuYDr1hGR+SKyV0Q+FZFxIvJ2DnEHE+OjIvKlf3+fiEilgOdvFpHNIpIuIsNyeX/aiMivIlI0YFkPEVnuv99aRL4WkV0isk1EnheREjns6w0ReSzg8f3+bbaKyC1Z1u0iIktFZI+I/CIiIwOenu//uUtE9onIhRnvbcD2F4nIQhHZ7f95UbDvTW5E5Dz/9rtEZKWIdAt47ioRWeXf5xYR+T//8kr+388uEdkpIgtExPJOhNkbbs4CzgBqAQNwfxMT/I9rAgeB53PZvg2wBqgE/BN4TUSkAOu+A3wHVARGAjfncsxgYrwR+AtwJlACyEg8DYEX/fs/23+86mRDVb8F9gOXZtnvO/77x4DB/tdzIXAZcHsuceOPoZM/niuAukDW8wP7gb7A6UAXYJCIXO1/rp3/5+mqWkZVv86y7zOAGcCz/tf2NDBDRCpmeQ2nvDd5xFwcmA584t/ub8AkEanvX+U1XDdgWaAR8Ll/+X1AKlAZqAI8CFjdlQizRG+OAyNU9Q9VPaiq6ar6gaoeUNW9wGjgkly236yqr6jqMWAiUBX3Dx30uiJSE2gFPKyqh1X1f8C0nA4YZIwTVHWtqh4E3gea+Zf3BD5S1fmq+gcw3P8e5ORdoDeAiJQFrvIvQ1UXq+o3qnpUVTcBL2cTR3au98e3QlX34z7YAl/fPFX9QVWPq+py//GC2S+4D4Z1qvqWP653gdWAL2CdnN6b3FwAlAGe9P+OPgc+wv/eAEeAhiJSTlV/V9UlAcurArVU9YiqLlArsBVxluhNmqoeynggIkki8rK/a2MPrqvg9MDuiyx+zbijqgf8d8vkc92zgZ0BywB+ySngIGP8NeD+gYCYzg7ctz/Rpud0LFzr/RoRKQlcAyxR1c3+OOr5uyV+9cfxOK51n5dMMQCbs7y+NiIy1981tRsYGOR+M/a9OcuyzUC1gMc5vTd5xqyqgR+Kgfu9FvchuFlEvhCRC/3LnwLWA5+IyAYRGRrcyzChZIneZG1d3QfUB9qoajlOdhXk1B0TCtuAM0QkKWBZjVzWL0yM2wL37T9mxZxWVtVVuITWmczdNuC6gFYDdf1xPFiQGHDdT4HewX2jqaGq5YGXAvabV2t4K65LK1BNYEsQceW13xpZ+tdP7FdVF6pqd1y3zlTcNwVUda+q3qeq5wDdgHtF5LJCxmLyyRK9yaosrs97l7+/d0S4D+hvIS8CRopICX9r0JfLJoWJcQrQVUT+7D9xOoq8/w/eAe7GfaD8O0sce4B9ItIAGBRkDO8DKSLS0P9BkzX+srhvOIdEpDXuAyZDGq6r6Zwc9j0TqCciN4pIMRG5AWiI62YpjG9xrf8hIlJcRNrjfkeT/b+zPiJSXlWP4N6T4wAi0lVE/uQ/F7Mbd14jt64yEwaW6E1WY4HTgB3AN8DHETpuH9wJzXTgMeA93Hj/7IylgDGq6krgDlzy3gb8jjtZmJuMPvLPVXVHwPL/wyXhvcAr/piDiWGW/zV8juvW+DzLKrcDo0RkL/Aw/taxf9sDuHMSX/pHslyQZd/pQFfct550YAjQNUvc+aaqh3GJvTPufX8B6Kuqq/2r3Axs8ndhDcT9PsGdbP4U2Ad8DbygqnMLE4vJP7HzIiYaich7wGpVDfs3CmPinbXoTVQQkVYicq6IFPEPP+yO6+s1xhSSXRlrosVZwH9wJ0ZTgUGqutTbkIyJD9Z1Y4wxcc66bowxJs5FXddNpUqVtHbt2l6HYYwxMWXx4sU7VLVyds9FXaKvXbs2ixYt8joMY4yJKSKS9YroE6zrxhhj4pwlemOMiXOW6I0xJs5FXR+9MSbyjhw5QmpqKocOHcp7ZeOpUqVKUb16dYoXLx70NpbojTGkpqZStmxZateuTc7zxhivqSrp6emkpqZSp06doLezrhtjDIcOHaJixYqW5KOciFCxYsV8f/OyRG+MAbAkHyMK8nuyRB+ntm2DN9/0OgpjTDSwRB+nbr8d+vWDVau8jsSYvKWnp9OsWTOaNWvGWWedRbVq1U48Pnz4cK7bLlq0iLvuuivPY1x00UUhiXXevHl07do1JPuKlKASvYh0EpE1IrI+uzkfReQZEVnmv60VkV0Bz/UTkXX+W78Qxm5y8M03MHWquz99uqehmDg1aRLUrg1FirifkyYVbn8VK1Zk2bJlLFu2jIEDBzJ48OATj0uUKMHRo0dz3DY5OZlnn302z2N89dVXhQsyhuWZ6P0TLo/DzSzTEOgtIg0D11HVwaraTFWbAc/hys0SMM1bG6A1MEJEKoT0FZhMVGHoUKhcGc4/H6ZN8zoiE28mTYIBA2DzZvf3tnmze1zYZJ9VSkoKAwcOpE2bNgwZMoTvvvuOCy+8kObNm3PRRRexZs0aIHMLe+TIkdxyyy20b9+ec845J9MHQJkyZU6s3759e3r27EmDBg3o06cPGVV8Z86cSYMGDWjZsiV33XVXni33nTt3cvXVV9OkSRMuuOACli9fDsAXX3xx4htJ8+bN2bt3L9u2baNdu3Y0a9aMRo0asWDBgtC+YbkIZnhla2C9qm4AEJHJuEkhcuoU6M3JOTCvBOao6k7/tnOATrip2UwYfPIJfPEFPPsspKfDqFGQluYSvzGhMGwYHDiQedmBA255nz7Zb1NQqampfPXVVxQtWpQ9e/awYMECihUrxqeffsqDDz7IBx98cMo2q1evZu7cuezdu5f69eszaNCgU8acL126lJUrV3L22WfTtm1bvvzyS5KTk7ntttuYP38+derUoXfv3nnGN2LECJo3b87UqVP5/PPP6du3L8uWLWPMmDGMGzeOtm3bsm/fPkqVKsX48eO58sorGTZsGMeOHeNA1jcxjILpuqkG/BLwONW/7BQiUguow8k5MIPaVkQGiMgiEVmUlpYWTNwmG8ePwwMPuK/SAwaAz+daXDNneh2ZiSc//5y/5YVx3XXXUbRoUQB2797NddddR6NGjRg8eDArV67MdpsuXbpQsmRJKlWqxJlnnslvv/12yjqtW7emevXqFClShGbNmrFp0yZWr17NOeecc2J8ejCJ/n//+x8333wzAJdeeinp6ens2bOHtm3bcu+99/Lss8+ya9cuihUrRqtWrZgwYQIjR47khx9+oGzZsgV9W/It1CdjewFTVPVYfjZS1fGqmqyqyZWt6VlgU6bA0qWuFV+yJLRoAWefbf30JrRq1szf8sIoXbr0ifvDhw+nQ4cOrFixgunTp+c4lrxkyZIn7hctWjTb/v1g1imMoUOH8uqrr3Lw4EHatm3L6tWradeuHfPnz6datWqkpKTwZgSHxQWT6LcANQIeV/cvy04vMnfL5GdbUwhHjsBDD7l++RtvdMtEoGtXmD0b/vjD2/hM/Bg9GpKSMi9LSnLLw2n37t1Uq+Y6BN54442Q779+/fps2LCBTZs2AfDee+/luc3FF1/MJP/JiXnz5lGpUiXKlSvHTz/9ROPGjfn73/9Oq1atWL16NZs3b6ZKlSrceuut9O/fnyVLloT8NeQkmES/EKgrInVEpAQumZ9yik9EGgAVgK8DFs8GOopIBf9J2I7+ZSbEJkyAdevg8cfB/00XcN03+/a5fntjQqFPHxg/HmrVco2JWrXc41D3z2c1ZMgQHnjgAZo3bx7yFjjAaaedxgsvvECnTp1o2bIlZcuWpXz58rluM3LkSBYvXkyTJk0YOnQoEydOBGDs2LE0atSIJk2aULx4cTp37sy8efNo2rQpzZs357333uPuu+8O+WvISVBzxorIVcBYoCjwuqqOFpFRwCJVneZfZyRQSlWHZtn2FuBB/8PRqjoht2MlJyerTTySPwcOQN267h/uyy/dP1+GgwehYkX461/huee8i9FEtx9//JHzzjvP6zA8t2/fPsqUKYOqcscdd1C3bl0GDx7sdVinyO73JSKLVTU5u/WDKmqmqjOBmVmWPZzl8cgctn0deD2Y45iCef552LoV3n03c5IHOO00uPxy10//7LOnPm+MOemVV15h4sSJHD58mObNm3Pbbbd5HVJIWPXKGLdrFzz5JHTuDO3aZb+Oz+cS/YoV0LhxRMMzJqYMHjw4KlvwhWUlEGLcU0/B77+7vvmcZFzzYaNvjElMluhj2LZtMHYs9OoFzZrlvF7VqpCcbInemERliT6GPfYYHD4Mjz6a97o+H3z7LWzfHv64jDHRxRJ9jPrpJzekrX9/+NOf8l4/4yrZGTPCH5sxJrpYoo9RI0ZA8eIwfHhw6zdrBtWrW/eNiU4dOnRg9uzMl9iMHTuWQYMG5bhN+/btyRiKfdVVV7Fr165T1hk5ciRjxozJ9dhTp05lVUA974cffphPP/00H9FnL5rKGVuij0Hffw/vvAN33+1KHARDxLXqP/kEbP5nE2169+7N5MmTMy2bPHlyUPVmwFWdPP300wt07KyJftSoUVx++eUF2le0skQfg4YNg/LlYciQ/G3n88H+/TB3bnjiMqagevbsyYwZM05MMrJp0ya2bt3KxRdfzKBBg0hOTub8889nxIgR2W5fu3ZtduzYAcDo0aOpV68ef/7zn0+UMgY3Rr5Vq1Y0bdqUa6+9lgMHDvDVV18xbdo07r//fpo1a8ZPP/1ESkoKU6ZMAeCzzz6jefPmNG7cmFtuuYU//LVEateuzYgRI2jRogWNGzdm9erVub4+r8sZ2zj6GLNggetnf+IJqJDPyv4dOkDp0q77pnPn8MRnYt8998CyZaHdZ7NmboRYTs444wxat27NrFmz6N69O5MnT+b6669HRBg9ejRnnHEGx44d47LLLmP58uU0adIk2/0sXryYyZMns2zZMo4ePUqLFi1o2bIlANdccw233norAA899BCvvfYaf/vb3+jWrRtdu3alZ8+emfZ16NAhUlJS+Oyzz6hXrx59+/blxRdf5J577gGgUqVKLFmyhBdeeIExY8bw6quv5vj6vC5nbC36GKLqyhBXrQpBzJx2ilKl4Ior4KOP3L6MiSaB3TeB3Tbvv/8+LVq0oHnz5qxcuTJTN0tWCxYsoEePHiQlJVGuXDm6det24rkVK1Zw8cUX07hxYyZNmpRjmeMMa9asoU6dOtSrVw+Afv36MX/+/BPPX3PNNQC0bNnyRCG0nHhdztha9DFk5kxXy+bFF0+tHhgsn89NM/j997mPvTeJK7eWdzh1796dwYMHs2TJEg4cOEDLli3ZuHEjY8aMYeHChVSoUIGUlJQcyxPnJSUlhalTp9K0aVPeeOMN5s2bV6h4M0odF6bM8dChQ+nSpQszZ86kbdu2zJ49+0Q54xkzZpCSksK9995L3759CxWrtehjRMakIuee6wqUFVSXLu7ErI2+MdGmTJkydOjQgVtuueVEa37Pnj2ULl2a8uXL89tvvzFr1qxc99GuXTumTp3KwYMH2bt3L9MD/tD37t1L1apVOXLkyInSwgBly5Zl7969p+yrfv36bNq0ifXr1wPw1ltvcckllxTotXldztha9DHi3Xfhhx/caJsss6LlS5Uq0Lq1S/TBDs00JlJ69+5Njx49TnThZJT1bdCgATVq1KBt27a5bt+iRQtuuOEGmjZtyplnnkmrVq1OPPfoo4/Spk0bKleuTJs2bU4k9169enHrrbfy7LPPnjgJC1CqVCkmTJjAddddx9GjR2nVqhUDBw4s0OvKmMu2SZMmJCUlZSpnPHfuXIoUKcL5559P586dmTx5Mk899RTFixenTJkyIZmgJKgyxZFkZYpPdfgwNGgA5crBkiVQpJDfw0aPdpOUbN3q+vuNsTLFsSW/ZYqt6yYGvPIKbNzoRtoUNsmD66cHu0rWmERhiT7K7d/vatm0awedOoVmn40bu/k9rZ/emMRgiT7K/etf8NtvrjUfqklDMq6SnTPHzUBlDEC0deOa7BXk92SJPoqlp8M//gHdusFFF4V23z6fS/Kffx7a/ZrYVKpUKdLT0y3ZRzlVJT09nVKlSuVrOxt1E8X+8Q/Yu9edPA219u2hTBnXfdOlS+j3b2JL9erVSU1NJS0tzetQTB5KlSpF9erV87WNJfootWWLm8z7ppugUaPQ779kSejY8eRVsjaXbGIrXrw4derU8ToMEybWdROlRo2CY8fgkUfCdwyfz32gLF0avmMYY7xniT4KrV0Lr70GAwdCOBtZdpWsMYnBEn0UGj7cFSAbNiy8x6lcGS68EKZNC+9xjDHeskQfZRYvhvffh8GDXbmCcPP53NW2W7aE/1jGGG9Yoo8yDz4IZ5wB//d/kTlexlWyH30UmeMZYyLPEn0UmTvXTfX34INuBqlIaNjQnQewfnpj4pcl+iiRMalI9epw++2RO27GVbKffQYhmMjGGBOFLNFHif/+F779FkaOhNNOi+yxfT43YXgIJr43xkQhS/RR4Ngx111Tvz706xf547dr50ogW/eNMfHJroyNAm+9BT/+CP/+NxTz4DdSogRceaU7IXv8eGhKIRtjoof9S3vsjz9gxAho2RKuvda7OHw++PVXN7zTGBNfLNF77KWX4Oef4cknva03c9VVriVv3TfGxB9L9B7auxceewwuuwwuv9zbWCpWdKWQLdEbE38s0Xvo6adhxw43qUg08Plg2TL45RevIzHGhFJQiV5EOonIGhFZLyJDc1jnehFZJSIrReSdgOXHRGSZ/2ZVVfzS0mDMGLjmGgiYqN5TdpWsMfEpzzEeIlIUGAdcAaQCC0VkmqquClinLvAA0FZVfxeRMwN2cVBVm4U27Nj3xBPuAqXHHvM6kpMaNIBzz3XdN4MGeR2NMSZUgmnRtwbWq+oGVT0MTAa6Z1nnVmCcqv4OoKrbQxtmfPn5Zxg3DlJS4LzzvI7mJBE3beFnn8G+fV5HY4wJlWASfTUgsNc21b8sUD2gnoh8KSLfiEingOdKicgi//KrCxdufBg50iXVESO8juRUPh8cPuwmDjfGxIdQnYwtBtQF2gO9gVdE5HT/c7VUNRm4ERgrIudm3VhEBvg/DBbF+5yVq1bBxIlwxx1Qs6bX0Zzqz392BdVs9I0x8SOYRL8FqBHwuLp/WaBUYJqqHlHVjcBaXOJHVbf4f24A5gHNsx5AVcerarKqJleuXDnfLyKWPPQQlC7tCphFo+LFoXNnmDHDXSVrjIl9wST6hUBdEakjIiWAXkDW0TNTca15RKQSritng4hUEJGSAcvbAqtIUN99Bx9+6GrNV6rkdTQ58/lg+3YXrzEm9uWZ6FX1KHAnMBv4EXhfVVeKyCgR6eZfbTaQLiKrgLnA/aqaDpwHLBKR7/3LnwwcrZNIVGHoUDd93+DBXkeTu86doWhR674xJl6IqnodQybJycm6aNEir8MIuTlzoGNH+Ne/4K67vI4mb+3bw86dsHy515EYY4IhIov950NPYVfGRsDx465PvlYtuO02r6MJjs8HP/wAmzd7HYkxprAs0UfABx+4qpCPPAIlS3odTXAyrpK17htjYp8l+jA7etSNtGnYEG66yetoglevnrtZojcm9lmiD7M33oC1a+Hxx90Jzlji88G8ea7KpjEmdlmiD6ODB91VsBdc4EoLxJqMq2Q/+cTrSIwxhWGJPozGjYMtW7yfVKSg2raFChWs+8aYWGeJPkx273YVKjt1gksu8TqagilW7ORVsseOeR2NMaagLNGHyZgxbhz64497HUnh+HxucpRvv/U6EmNMQVmiD4PffnOzR91wAzQ/pbJPbOnUybXsp9mUMcbELEv0YfDYY/DHH/Doo15HUninnw7t2lk/vTGxzBJ9iH3+Obz8MvTvD3Xreh1NaPh8rrzyhg1eR2KMKQhL9CFy8CDccw9cdhnUrh2dk4oUlF0la0xss0QfAt995/ri//UvuPNOWLYMqlb1OqrQOfdcN+WhJXpjYpMl+kI4fBgefhguugj273cVKp97DpKSvI4s9Hw++OILN2zUGBNbLNEX0IoV7orXRx+FPn1cpcfLL/c6qvDx+VzdntmzvY7EGJNflujz6dgxeOopaNkSUlPdjFETJ7rRKfHswguhYkXrvjEmFhXzOoBYsmED9OsH//sf9OgBL70EZ57pdVSRUbQoXHWVu0r26FE3tt4YExusRR8EVRg/Hpo0cTMuTZzoaswnSpLP4PO5q32//trrSIwx+WGJPg9bt0KXLm5mqAsucH3zffvGZpGywrrySihe3LpvjIk1luhzMXkyNGrkarI/95wr11ujhtdReadcOVegzRK9MbHFEn020tNdnZrevaF+fTcu/s47oYi9W/h8sHo1rF/vdSTGmGBZ6spixgzXiv/wQxg9GhYscFPqGceukjUm9lii99uzx9Wn6doVKleGhQvhwQdtdElWderA+edbojcmlliix13x2bQpTJgAQ4e6JN+0qddRRS+fD+bPh99/9zoSY0wwEjrRHzoE990HHTq4ceILFrhZoUqW9Dqy6Natm7tw7OOPvY7EGBOMhE30ixZBixZugpBBg+D7713NGpO31q1d95Z13xgTGxIu0R85AiNHujHxe/a42i3jxkHp0l5HFjuKFnXXFsya5d5PY0x0S6hEv2qVq9nyyCNu6OQPP0DHjl5HFZt8Pti1C7780utIjDF5SYhEf/y466Jp0QI2bYIpU+Ctt6BCBa8ji10dO0KJEtZ9Y0wsiPtEv3GjO9l6333uEv6VK+Haa72OKvaVKePeV0v0xkS/uE30qvDaa64Q2dKlbujk1KlQpYrXkcUPnw/WrYM1a7yOxBiTm7hM9Nu2uSTUvz+0auX64lNSErMQWTh17ep+WqvemOgWd4n+/fddCYPPPoOxY+HTT6FWLa+jik+1arlvTJbojYlucZPof/8dbrzRFSM791zXXXP33VaILNx8PjfyZudOryMxxuQkbtLgkSOulMGjj8JXX0GDBl5HlBh8PneV7KxZXkdijMlJUIleRDqJyBoRWS8iQ3NY53oRWSUiK0XknYDl/URknf/WL1SBZ3XmmbB2LTz0kBUii6RWrdwJbuu+MSZ65ZkSRaQoMA64AkgFForINFVdFbBOXeABoK2q/i4iZ/qXnwGMAJIBBRb7tw1LOSy7ujXyihRxV8l+8AEcPuzG1htjokswLfrWwHpV3aCqh4HJQPcs69wKjMtI4Kq63b/8SmCOqu70PzcH6BSa0E208Plg925XFM4YE32CSfTVgF8CHqf6lwWqB9QTkS9F5BsR6ZSPbRGRASKySEQWpaWlBR+9iQpXXOEqflr3jTHRKVQnY4sBdYH2QG/gFRE5PdiNVXW8qiaranLlypVDFJKJlNKl4bLLXKJX9ToaY0xWwST6LUDglNjV/csCpQLTVPWIqm4E1uISfzDbmjjg88GGDfDjj15HYozJKphEvxCoKyJ1RKQE0AuYlmWdqbjWPCJSCdeVswGYDXQUkQoiUgHo6F9m4oxdJWtM8I4edeVDZsxwBRdvu83Vjrr55vAcL89RN6p6VETuxCXoosDrqrpSREYBi1R1GicT+irgGHC/qqYDiMijuA8LgFGqapfWxKHq1aF5c5fo//53r6MxxnuqsH27qwW1dm3mnz/95JJ9hjPOgPr1oWrV8MQiGmWdqsnJybpo0SKvwzAFMGIEPPYY/PYbVKrkdTTGRMb+/a51npHEMxL62rVuNFqGEiWgbl2X0OvVy/yzYsXCxyEii1U1Obvn7NIiEzI+H4waBTNnQt++XkdjTOgcOwabN2ffOk9NzbxujRoueffpkzmZ16zpZmfzgiV6EzItWrivntOnW6I3sUcV0tOzT+br17sLAjOUL++Sd/v2mZP5n/4UnRduWqI3IVOkiDspO3myXSVrYscXX8ADD8Dq1a44YobixV2BxHr13NXfgQm9cuXYKntuid6ElM8Hr7zi/nmuuMLraIzJ3eHDbq6Ko0fh+uszJ/PateOnblacvAwTLS67DEqVct03luhNtHv5ZTeP9KxZ0CmOi7PETZliEx2SkuDyy+0qWRP99u51Zc3bt3fzScczS/Qm5Hw+10paudLrSIzJ2TPPQFoaPPFEbPW3F4QlehNydpWsiXZpaTBmDPToARdc4HU04Rc3iX7SJHfypEgR93PSJK8jSlxnnw0tW8K0rIUyjIkSjz/uLnQaPdrrSCIjLhL9pEkwYIC7oEHV/RwwwJK9l3w++PZbdwm4MdFk82Z44QU32ua887yOJjLiItEPGwYHDmReduCAW2680a2b+9CdMcPrSIzJbMQI1yc/cqTXkUROXCT6n3/O33ITfs2auUJn1k9vosmKFfDmm3Dnna5UQaKIi0Rfs2b+lpvwE3EnZT/5BA4d8joaY5xhw6BsWXclbCKJi0Q/erQbvx0oKSlxTrREK5/PnfCaN8/rSIyBr75yAwSGDAlNtchYEheJvk8fGD8eatVyLclatdzjPn28jiyxXXqp+8C17hvjNVUYOhSqVIF77vE6msiLi0QPLqlv2gTHj7ufXiR5G+KZWalS0LmzG+HQurW7CnHZMrti1kTerFmwYAE8/HB0VpcMN5t4JEQyhngGjv5JSrJvFjt2uHoi06fDd9+5JF+9uuu/79bNTZ9WqpTXUZp4dvy4m/1s/343p3Hx4l5HFB65TTxiiT5Eatd243OzqlXLfcMwbuapGTNc0v/kE/ehmJTkip/5fK4U7FlneR2liTeTJsFNN8E770Dv3l5HEz6W6COgSJHsuyREXIvCZHboEMyd65L+Rx/BL7+45a1bu6Tv80GTJvFfg8SE1+HD0KCBmyhk8WL3fxqvckv0cfyyI8uGeOZPYP/95s2wdKmbhlAVhg934/Br14Y77oCPP4Y//vA6YhOLxo+HjRtd4bJ4TvJ5sRZ9iFgffehs23ayi2fOHDh40J1A69jxZBfPmWd6HaWJdvv2uRmiGjaEzz+P/2+HNjl4BGQk82HD3BW5NWu6cfyW5POvalXo39/dDh482cUzfTp8+KH7h23T5mQXT6NG8f9PbPLvmWdcraX//tf+PqxFb2KGqhuemZH0M/5Matd2o3h8PrjkEihZ0ssoTTRIS3Ot+csvh//8x+toIsP66I0nQn1dgYgbJvfww7BwIWzZ4rrGGjeG115zswRVqgQ9e8LEie6f3SSmJ55IrDLEebEWvQmLSJ+zOHDA9cNmjOLZutV9MFx44ckunoYN7St8Iti82U3wfdNNrgGQKGx4pYk4L68rUIUlS0528SxZ4pa3auX6bdu2De/xjbf+8hd4911Yty6xKlRa142JOC9LR4u4Ga5GjnRjp1NT4fnnXSv/z3+GXr2y/xAysW/lysQsQ5wXS/RxKBpq7kTTdQXVqrnx+GvWuEknpk2D+vXhoYfcELxEs2ULjB3rylPEm2HDoEyZxCtDnCdVjapby5Yt1RTc22+rJiWpug4Md0tKcssTMY7s/Pyzap8+LqazzlJ9/XXVY8e8jir8fvlF9Y47VEuWdK+9TRvV/fu9jip0vvzSva7HHvM6Em8AizSHvOp5Ys96s0RfOLVqZU6uGbdatSIfy9tvu+OKuJ/RkOQDff21S3ag2qKF6hdfeB1RePz8s+qgQaolSqgWK6bav7/qiy+630u3bqpHjngdYeEdP6568cWqVaqo7tvndTTesESfQESyT/QiXkcWnY4dU500SbV6dfc+9eypumGD11GFxubNqgMHqhYv7m4DBqhu3Hjy+eeec6950CCXKGPZjBnutYwb53Uk3rFEn0CiqUUfS/bvV33kEde9VKKE6tChqrt3ex1VwWzc6JJ6RoIfONAl/ezcf7/7+3j88YiGGFLHjqk2aaJ6zjmqf/zhdTTesUSfQKK5bzwWpKaq9u3r3rcqVVRfeUX16FGvowrOhg2uW6ZYMfdhdfvtrtsmN8eOqfbu7V7vm29GJs5Qe/ttF/8773gdibcs0SeYaO8bjwXffqt60UXuP6RpU9W5c72OKGc//aR6yy0uwZcsqXrnne7Ea7AOHVLt0MFtP2dO+OIMhz/+UK1TR7VZs8Q4oZ4bS/TGFMDx46qTJ6vWrOn+U3r0UF2/3uuoTlq3TjUlRbVoUZfg//Y3942kIH7/XbVRI9WyZVWXLQtpmGGVcZ5h1iyvI/Febok+qHH0ItJJRNaIyHoRGZrN8ykikiYiy/y3/gHPHQtYPi0kY0KNiQARuOEGWL0aHnvMzYrVsCEMGQK7d3sX17p1kJLiJtSYPNldHLRhAzz7rLtmoCBOP93Nq1quHFx1VWQubCusffvcPMTt27s6RyYXOX0CZNyAosBPwDlACeB7oGGWdVKA53PYfl9exwi8WYveRKstW1wLGlQrV1Z96aXI9t+vWaN6882qRYqonnaa6uDBqlu3hvYYy5erliunet55qjt3hnbfoTZqlPtdfP2115FEBwrZom8NrFfVDap6GJgMdA/1B44x0e7ss2HCBFc5s359GDjQVdP87LPwHnf1aleg67zzYMoUGDzYteCfftrV7g+lxo1h6lRYvx6uvtpN+RiN0tLgqaegRw+44AKvo4l+wST6asAvAY9T/cuyulZElovIFBEJrDJRSkQWicg3InJ1dgcQkQH+dRalWW1ZE+WSk2H+fPj3v2HvXlfzvHt316USSj/+CDfe6LqLPvwQ7rvPFYQbMya8k6h36ODKPM+fD/36Reecx1aGOJ9yaurrya6XnsCrAY9vJks3DVARKOm/fxvwecBz1fw/zwE2AefmdjzrujGx5OBB1SeeUC1Txo1Zv/ded2KzMFasUL3hBjdqqnRp1SFDVLdvD0m4+fLPf7qukXvvjfyxc7Npkxs+esstXkcSXSjMqBvgQmB2wOMHgAdyWb8osDuH594AeuZ2PEv0JhZt26b617+65FypkuoLL+S/tMAPP6hed53bR5ky7qKttLTwxBuM48fdUE1QfeYZ7+LIKiXFjTLK6xqBRFPYRF8M2ADU4eTJ2POzrFM14H4P4Bv//QoBLf1KwDqynMjNerNEb2LZkiWq7dq5/6zzz1edPTvvbb7/XvXaa902ZcqoPvig6o4d4Y81GEePumGlIqrvv+91NO7bTpEiqvfd53Uk0adQid5tz1XAWtzom2H+ZaOAbv77TwAr/R8Cc4EG/uUXAT/4l/8A/DWvY1miN6EW6QvIjh9X/eADdyEPqHbporp69anrLVumes01bp2yZVUfekg1PT28sRXEgQPu4rGSJVXnz/c2lu7d3aigaPkgjCaFTvSRvFmiN6HkZUmIQ4dU//EPl8SLFVO9+26XyJcsUb36ahdLuXKqw4dHZ4IPtGOHav36qqefrrpypTcxJHoZ4rzkluhtKkET17yc0jDDb7+5Cc1feQVKl3YX+pQvD/fcA3ffDRUqRCaOwtq40c3BW7IkfP21G24aKapwySWwdi389JN7H01mNpWgSVheTmmYoUoVePllWLrUDcN85BH3ITNyZOwkeYA6dWDGDEhPd1fP7tkTuWPPmgULFrgPTEvy+WctehPXoqFFH28+/hi6doVLL4WPPoISJcJ7vOPH3YVp+/a5awvCfbxYZS16k7BGj4akpMzLkpLsQpvC6NTJdUPNmQO33uq6VcLp3Xdh+XJXb8iSfMFYojdxrU8fGD/eteBF3M/x491yU3B/+YvrgnrzTRg+PHzHOXzY7b9ZM1dgzhRMMa8DMCbc+vSxxB4Ow4fDL7+4b0c1asBtt4X+GOPHu5PAs2ZBEWuWFpglemNMgYjAiy/C1q1w++1uFI7PF7r9Z5QhvuQSK0NcWPYZaYwpsGLF4L33oEUL17Xy7beh2/czz8D27fDkk+5DxRScJXpjTKGUKeNG31St6kbjrF9f+H3u2OHKEF99tZUhDgVL9MaYQqtSxfWjq7pROdu3F25/jz9uZYhDyRK9MSYk6tWD6dNhyxbXst+/v2D7+flnGDfO1cJv2DC0MSYqS/TGmJC58EI3j+3ixdCrFxw9mv99jBjh+uQfeST08SUqS/TGmJDq3h2ef971299xR/4uqFq50o3Nv/NON2TThIYNrzTGhNygQa4L5sknoWZNGDYsuO2GDXMndx94ILzxJRpr0RsTIZMmudo7RYq4n5MmeR1ReD3+uJvU/KGH3By0efn6a/jvf2HIEKhYMfzxJRJr0RsTAZMmwYABcOCAe7x5s3sM8XvVrgi89hps2wb9+7vhlx07Zr+uKgwd6kbv3HNPRMNMCNaiNyYChg07meQzHDgQfJdGrCpRAj74wI2eufZaWLYs+/U+/hjmz7cyxOFiid6YCIiGuvgZIt2FVL48zJzpau937nxq2ejjx12f/DnnuJa/CT1L9MZEQM2a+VseLhldSJs3u+6SjC6kcCf7atXcBVWHDrkLqnbuPPnc5Mnw/fdWhjicLNEbEwHRUhffyy6k88+HqVNhwwY3BPPQIStDHCl2MtaYCMg44TpsmOuuqVnTJflIn4j1ugvpkkvcOPleveDmm6FdO5f4rQxxeNlUgsYkkGiZWvHpp+G++1xyv/himDvXKlQWlk0laIwBoqcLafBgN4yySBErQxwJluiNSSDRMrWiiGvV//qrlSGOBOujNybBRMvUiiJ2BWykWIveGGPinCV6Y4yJc5bojTEmzlmiN8aYOGeJ3hhj4pwlemOMiXOW6I0xJs5ZojfGRFyizbblNbtgyhgTUYk425bXgmrRi0gnEVkjIutFZGg2z6eISJqILPPf+gc8109E1vlv/UIZvDEm9iTqbFteyrNFLyJFgXHAFUAqsFBEpqnqqiyrvqeqd2bZ9gxgBJAMKLDYv+3vIYneGBNzvC6VnIiCadG3Btar6gZVPQxMBroHuf8rgTmqutOf3OcAnQoWqjEmHkTLbFuJJJhEXw34JeBxqn9ZVteKyHIRmSIiNfKzrYgMEJFFIrIoLS0tyNCNMbEoWkolJ5JQjbqZDtRW1Sa4VvvE/GysquNVNVlVkytXrhyikIwx0ShaSiVD4oz+CWbUzRagRsDj6v5lJ6hqesDDV4F/BmzbPsu28/IbpDEmvkRDqeREGv0TTIt+IVBXROqISAmgFzAtcAURqRrwsBvwo//+bKCjiFQQkQpAR/8yY4zxVCKN/smzRa+qR0XkTlyCLgq8rqorRWQUsEhVpwF3iUg34CiwE0jxb7tTRB7FfVgAjFLVnWF4HcYYky+JNPrHJgc3xiSkaJkoPVRscnBjjMkikUb/WKI3xiSkaBr9E25W68YYk7CiYfRPJFiL3hhj4pwlemOMiXOW6I0xJs5ZojfGmDhnid4YY+KcJXpjjIlzluiNMSbOWaI3xpg4Z4neGGM8Fu66+HZlrDHGeCgSdfGtRW+MMR6KRF18S/TGGOOhSNTFt0RvjDEeqlkzf8sLwhK9McZ4KBJ18S3RG2OMhyJRF99G3RhjjMfCXRffWvTGGBPnLNEbY0ycs0RvjDFxzhK9McbEOUv0xhgT50RVvY4hExFJAzZ7HUchVQJ2eB1EFLH3IzN7P06y9yKzwrwftVS1cnZPRF2ijwciskhVk72OI1rY+5GZvR8n2XuRWbjeD+u6McaYOGeJ3hhj4pwl+vAY73UAUcbej8zs/TjJ3ovMwvJ+WB+9McbEOWvRG2NMnLNEb4wxcc4SfQiJSA0RmSsiq0RkpYjc7XVMXhORoiKyVEQ+8joWr4nI6SIyRURWi8iPInKh1zF5SUQG+/9PVojIuyJSyuuYIklEXheR7SKyImDZGSIyR0TW+X9WCMWxLNGH1lHgPlVtCFwA3CEiDT2OyWt3Az96HUSU+Bfwsao2AJqSwO+LiFQD7gKSVbURUBTo5W1UEfcG0CnLsqHAZ6paF/jM/7jQLNGHkKpuU9Ul/vt7cf/I1byNyjsiUh3oArzqdSxeE5HyQDvgNQBVPayquzwNynvFgNNEpBiQBGz1OJ6IUtX5wM4si7sDE/33JwJXh+JYlujDRERqA82Bbz0OxUtjgSHAcY/jiAZ1gDRggr8r61URKe11UF5R1S3AGOBnYBuwW1U/8TaqqFBFVbf57/8KVAnFTi3Rh4GIlAE+AO5R1T1ex+MFEekKbFfVxV7HEiWKAS2AF1W1ObCfEH0tj0X+vufuuA/As4HSInKTt1FFF3Vj30My/t0SfYiJSHFckp+kqv/xOh4PtQW6icgmYDJwqYi87W1InkoFUlU14xveFFziT1SXAxtVNU1VjwD/AS7yOKZo8JuIVAXw/9weip1aog8hERFcH+yPqvq01/F4SVUfUNXqqlobd5Ltc1VN2Babqv4K/CIi9f2LLgNWeRiS134GLhCRJP//zWUk8MnpANOAfv77/YD/hmKnluhDqy1wM671usx/u8rroEzU+BswSUSWA82Ax70Nxzv+bzZTgCXAD7hclFDlEETkXeBroL6IpIrIX4EngStEZB3uW8+TITmWlUAwxpj4Zi16Y4yJc5bojTEmzlmiN8aYOGeJ3hhj4pwlemOMiXOW6I0xJs5ZojfGmDj3/00phSZjeQdxAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_model = keras.models.load_model(\"convnet_from_scratch1.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RTvbHQ_nzf9d",
        "outputId": "53cd5fbb-e737-4cfd-9b13-8f79fe3ce84c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 1s 30ms/step - loss: 0.4820 - accuracy: 0.7610\n",
            "Test accuracy: 0.761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test accuracy with no data augmentation=76.1%"
      ],
      "metadata": {
        "id": "o_cp9IS2lvvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Augmentation"
      ],
      "metadata": {
        "id": "d-r4OSJas7aC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation is a technique used to increase the size of a training set by creating new, modified versions of the original data. This helps to reduce overfitting and improve the generalization ability of the model. "
      ],
      "metadata": {
        "id": "AxtfciqimEPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "KAe8NjC9zwxg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YeoJoJ2vz6Kc",
        "outputId": "a1009a39-91b0-489b-9469-c1f70c80984a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation1.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tkPmOiOxz-Hs",
        "outputId": "143b9304-0c9d-4d6f-d0f3-a963e2a1832f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 24s 214ms/step - loss: 0.6962 - accuracy: 0.4993 - val_loss: 0.6927 - val_accuracy: 0.5090\n",
            "Epoch 2/10\n",
            "94/94 [==============================] - 20s 207ms/step - loss: 0.6966 - accuracy: 0.5350 - val_loss: 0.6847 - val_accuracy: 0.5900\n",
            "Epoch 3/10\n",
            "94/94 [==============================] - 19s 198ms/step - loss: 0.6885 - accuracy: 0.5800 - val_loss: 0.6588 - val_accuracy: 0.6390\n",
            "Epoch 4/10\n",
            "94/94 [==============================] - 19s 199ms/step - loss: 0.6447 - accuracy: 0.6253 - val_loss: 0.6110 - val_accuracy: 0.6580\n",
            "Epoch 5/10\n",
            "94/94 [==============================] - 19s 203ms/step - loss: 0.6666 - accuracy: 0.6560 - val_loss: 0.6287 - val_accuracy: 0.6700\n",
            "Epoch 6/10\n",
            "94/94 [==============================] - 19s 199ms/step - loss: 0.6137 - accuracy: 0.6713 - val_loss: 0.7161 - val_accuracy: 0.5460\n",
            "Epoch 7/10\n",
            "94/94 [==============================] - 19s 205ms/step - loss: 0.5742 - accuracy: 0.7017 - val_loss: 0.6961 - val_accuracy: 0.6520\n",
            "Epoch 8/10\n",
            "94/94 [==============================] - 19s 201ms/step - loss: 0.5688 - accuracy: 0.7010 - val_loss: 0.5801 - val_accuracy: 0.7030\n",
            "Epoch 9/10\n",
            "94/94 [==============================] - 23s 244ms/step - loss: 0.5509 - accuracy: 0.7263 - val_loss: 0.6482 - val_accuracy: 0.7080\n",
            "Epoch 10/10\n",
            "94/94 [==============================] - 19s 196ms/step - loss: 0.5373 - accuracy: 0.7327 - val_loss: 0.5550 - val_accuracy: 0.7300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data augmentation to the model did not bring any better results,but yet can be checked by increasing the training sample size and trying on data augmentation on it."
      ],
      "metadata": {
        "id": "slxlwnT9mZR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy=73.2%\n",
        "val_acc=73%\n",
        "test_acc=72.5%"
      ],
      "metadata": {
        "id": "3JsM0HXetkF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation1.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MzTumxSy0BP-",
        "outputId": "fc5eb4c0-3ae4-4370-fb3e-6c5c65d3dcaa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 31ms/step - loss: 0.5222 - accuracy: 0.7250\n",
            "Test accuracy: 0.725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test accuracy was not improved"
      ],
      "metadata": {
        "id": "hIzLY25lnF23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2)Increase training sample size."
      ],
      "metadata": {
        "id": "w6Sl6UtbnTuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempted to increase training sample size from 1000 to 1500."
      ],
      "metadata": {
        "id": "v9_TgaZinT0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_2\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1500)\n",
        "make_subset(\"validation\", start_index=1500, end_index=2000)\n",
        "make_subset(\"test\", start_index=2000, end_index=2500)"
      ],
      "metadata": {
        "id": "dO4Vbaw50Eo-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "t_5GYUQ30M0d",
        "outputId": "cc955554-f0fc-4f99-eb05-15700d0e17da"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "mIaeIzz81QdB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch2.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SW2Cg4be1T3y",
        "outputId": "3a00d602-bbd0-4928-ba98-9b21ccd10e9a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "94/94 [==============================] - 7s 60ms/step - loss: 0.6956 - accuracy: 0.5257 - val_loss: 0.7159 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "94/94 [==============================] - 7s 68ms/step - loss: 0.6847 - accuracy: 0.5787 - val_loss: 0.6825 - val_accuracy: 0.5510\n",
            "Epoch 3/10\n",
            "94/94 [==============================] - 6s 57ms/step - loss: 0.6424 - accuracy: 0.6353 - val_loss: 0.6330 - val_accuracy: 0.6290\n",
            "Epoch 4/10\n",
            "94/94 [==============================] - 6s 66ms/step - loss: 0.5985 - accuracy: 0.6797 - val_loss: 0.6603 - val_accuracy: 0.6390\n",
            "Epoch 5/10\n",
            "94/94 [==============================] - 6s 66ms/step - loss: 0.5604 - accuracy: 0.7093 - val_loss: 0.5662 - val_accuracy: 0.6970\n",
            "Epoch 6/10\n",
            "94/94 [==============================] - 9s 89ms/step - loss: 0.5173 - accuracy: 0.7493 - val_loss: 0.6021 - val_accuracy: 0.6840\n",
            "Epoch 7/10\n",
            "94/94 [==============================] - 8s 81ms/step - loss: 0.4817 - accuracy: 0.7727 - val_loss: 0.6035 - val_accuracy: 0.7020\n",
            "Epoch 8/10\n",
            "94/94 [==============================] - 6s 58ms/step - loss: 0.4422 - accuracy: 0.7857 - val_loss: 0.5588 - val_accuracy: 0.7270\n",
            "Epoch 9/10\n",
            "94/94 [==============================] - 7s 67ms/step - loss: 0.4106 - accuracy: 0.8067 - val_loss: 0.6010 - val_accuracy: 0.7320\n",
            "Epoch 10/10\n",
            "94/94 [==============================] - 5s 56ms/step - loss: 0.3638 - accuracy: 0.8450 - val_loss: 0.6196 - val_accuracy: 0.7360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch2.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OBQjAUI41WP_",
        "outputId": "d37b9867-b6a0-4ad2-e031-4d2c188ae4ef"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 1s 31ms/step - loss: 0.5064 - accuracy: 0.7570\n",
            "Test accuracy: 0.757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy=84.5%\n",
        "val_acc=73.6%\n",
        "test_acc=75.7%"
      ],
      "metadata": {
        "id": "RroS5L3Yn057"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##using data augmentation"
      ],
      "metadata": {
        "id": "9n1gpXazuhgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "NFUA98Tw1bB7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HL7UajML1dZN",
        "outputId": "1464d1fa-214f-4620-d87f-ab17a2a761ab"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation2.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qW1TKQ8G1gC_",
        "outputId": "cea60ad8-949f-4091-9956-b8e99b029b91"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 29s 250ms/step - loss: 0.6952 - accuracy: 0.5070 - val_loss: 0.6813 - val_accuracy: 0.5300\n",
            "Epoch 2/10\n",
            "94/94 [==============================] - 19s 200ms/step - loss: 0.6789 - accuracy: 0.5610 - val_loss: 0.6796 - val_accuracy: 0.5580\n",
            "Epoch 3/10\n",
            "94/94 [==============================] - 20s 202ms/step - loss: 0.6558 - accuracy: 0.6190 - val_loss: 0.6600 - val_accuracy: 0.5860\n",
            "Epoch 4/10\n",
            "94/94 [==============================] - 20s 207ms/step - loss: 0.6209 - accuracy: 0.6613 - val_loss: 0.6479 - val_accuracy: 0.6300\n",
            "Epoch 5/10\n",
            "94/94 [==============================] - 19s 199ms/step - loss: 0.6055 - accuracy: 0.6717 - val_loss: 0.6506 - val_accuracy: 0.6320\n",
            "Epoch 6/10\n",
            "94/94 [==============================] - 20s 205ms/step - loss: 0.5801 - accuracy: 0.7050 - val_loss: 0.5994 - val_accuracy: 0.6680\n",
            "Epoch 7/10\n",
            "94/94 [==============================] - 19s 195ms/step - loss: 0.5708 - accuracy: 0.7090 - val_loss: 0.5796 - val_accuracy: 0.7010\n",
            "Epoch 8/10\n",
            "94/94 [==============================] - 19s 199ms/step - loss: 0.5569 - accuracy: 0.7133 - val_loss: 0.5828 - val_accuracy: 0.6960\n",
            "Epoch 9/10\n",
            "94/94 [==============================] - 20s 208ms/step - loss: 0.5396 - accuracy: 0.7420 - val_loss: 0.5980 - val_accuracy: 0.6820\n",
            "Epoch 10/10\n",
            "94/94 [==============================] - 19s 200ms/step - loss: 0.5338 - accuracy: 0.7317 - val_loss: 0.5668 - val_accuracy: 0.7090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation2.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_Yoobnl81i6_",
        "outputId": "f5856af7-a726-4d68-facd-875c6151488a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 30ms/step - loss: 0.5404 - accuracy: 0.7140\n",
            "Test accuracy: 0.714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy=73.1%\n",
        "val_acc=70.9%\n",
        "test_acc=71.4%"
      ],
      "metadata": {
        "id": "SJm_AdHtupyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Finding the ideal training sample size"
      ],
      "metadata": {
        "id": "fV79oAw9v05i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set the training, validation, and test set sizes, respectively, to 1500, 1000, and 500."
      ],
      "metadata": {
        "id": "PAxxdZYfv1Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, shutil, pathlib\n",
        "\n",
        "original_dir = pathlib.Path(\"train\")\n",
        "new_base_dir = pathlib.Path(\"cats_vs_dogs_small_3\")\n",
        "\n",
        "def make_subset(subset_name, start_index, end_index):\n",
        "    for category in (\"cat\", \"dog\"):\n",
        "        dir = new_base_dir / subset_name / category\n",
        "        os.makedirs(dir, exist_ok=True)\n",
        "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
        "        for fname in fnames:\n",
        "            shutil.copyfile(src=original_dir / fname,\n",
        "                            dst=dir / fname)\n",
        "\n",
        "make_subset(\"train\", start_index=0, end_index=1500)\n",
        "make_subset(\"validation\", start_index=1500, end_index=2500)\n",
        "make_subset(\"test\", start_index=2500, end_index=3000)"
      ],
      "metadata": {
        "id": "o41aUwYt1oXz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lkwVQ6_I1wMp",
        "outputId": "fec1c68f-5a8a-4b30-b015-fe46c7b4d3fc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "     "
      ],
      "metadata": {
        "id": "FF2P2yvv1yt5"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch3.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "H-9wYXHQ11Lc",
        "outputId": "0e1236d8-9e1b-4280-a346-2800b3f25055"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "94/94 [==============================] - 10s 92ms/step - loss: 0.7036 - accuracy: 0.4997 - val_loss: 0.6915 - val_accuracy: 0.5145\n",
            "Epoch 2/10\n",
            "94/94 [==============================] - 11s 117ms/step - loss: 0.6823 - accuracy: 0.5683 - val_loss: 0.6565 - val_accuracy: 0.6170\n",
            "Epoch 3/10\n",
            "94/94 [==============================] - 11s 116ms/step - loss: 0.6412 - accuracy: 0.6367 - val_loss: 0.6451 - val_accuracy: 0.6410\n",
            "Epoch 4/10\n",
            "94/94 [==============================] - 8s 79ms/step - loss: 0.5968 - accuracy: 0.6883 - val_loss: 0.6245 - val_accuracy: 0.6520\n",
            "Epoch 5/10\n",
            "94/94 [==============================] - 8s 80ms/step - loss: 0.5436 - accuracy: 0.7167 - val_loss: 0.6038 - val_accuracy: 0.6835\n",
            "Epoch 6/10\n",
            "94/94 [==============================] - 7s 70ms/step - loss: 0.5107 - accuracy: 0.7433 - val_loss: 0.5490 - val_accuracy: 0.7190\n",
            "Epoch 7/10\n",
            "94/94 [==============================] - 7s 68ms/step - loss: 0.4652 - accuracy: 0.7773 - val_loss: 0.5205 - val_accuracy: 0.7450\n",
            "Epoch 8/10\n",
            "94/94 [==============================] - 8s 78ms/step - loss: 0.4221 - accuracy: 0.8033 - val_loss: 0.5395 - val_accuracy: 0.7480\n",
            "Epoch 9/10\n",
            "94/94 [==============================] - 7s 68ms/step - loss: 0.3790 - accuracy: 0.8360 - val_loss: 0.5510 - val_accuracy: 0.7545\n",
            "Epoch 10/10\n",
            "94/94 [==============================] - 8s 80ms/step - loss: 0.3331 - accuracy: 0.8560 - val_loss: 0.6245 - val_accuracy: 0.7375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch3.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8j4o2p3x13se",
        "outputId": "524cdb4b-18dc-449b-90ce-bc7980d2ccf1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 1s 30ms/step - loss: 0.5511 - accuracy: 0.7260\n",
            "Test accuracy: 0.726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy=85.6%\n",
        "val_Acc=73.7%\n",
        "test_Acc=72.6%"
      ],
      "metadata": {
        "id": "zjs73H7owCZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using Data augmentation"
      ],
      "metadata": {
        "id": "xnZ1z6A_wG7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "RJ5q36MK17BE"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FrTYAeg019iF",
        "outputId": "ed1dad1a-69e5-4f2b-b2c1-1d8d6b590c3a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"convnet_from_scratch_with_augmentation3.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zuRFe1Du1_9G",
        "outputId": "22c26d7e-478a-4f89-dc31-034f6d9fe4a1"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 29s 260ms/step - loss: 0.6947 - accuracy: 0.4980 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "94/94 [==============================] - 27s 284ms/step - loss: 0.6936 - accuracy: 0.5030 - val_loss: 0.6845 - val_accuracy: 0.5845\n",
            "Epoch 3/10\n",
            "94/94 [==============================] - 24s 255ms/step - loss: 0.6873 - accuracy: 0.5483 - val_loss: 0.6806 - val_accuracy: 0.5860\n",
            "Epoch 4/10\n",
            "94/94 [==============================] - 21s 222ms/step - loss: 0.6885 - accuracy: 0.5473 - val_loss: 0.6808 - val_accuracy: 0.5795\n",
            "Epoch 5/10\n",
            "94/94 [==============================] - 21s 221ms/step - loss: 0.6907 - accuracy: 0.5230 - val_loss: 0.6880 - val_accuracy: 0.5395\n",
            "Epoch 6/10\n",
            "94/94 [==============================] - 22s 236ms/step - loss: 0.6800 - accuracy: 0.5737 - val_loss: 0.6632 - val_accuracy: 0.5890\n",
            "Epoch 7/10\n",
            "94/94 [==============================] - 23s 235ms/step - loss: 0.6960 - accuracy: 0.5217 - val_loss: 0.6760 - val_accuracy: 0.5645\n",
            "Epoch 8/10\n",
            "94/94 [==============================] - 21s 219ms/step - loss: 0.6951 - accuracy: 0.5030 - val_loss: 0.6912 - val_accuracy: 0.5140\n",
            "Epoch 9/10\n",
            "94/94 [==============================] - 21s 216ms/step - loss: 0.6899 - accuracy: 0.5290 - val_loss: 0.6861 - val_accuracy: 0.5475\n",
            "Epoch 10/10\n",
            "94/94 [==============================] - 21s 227ms/step - loss: 0.6867 - accuracy: 0.5377 - val_loss: 0.6860 - val_accuracy: 0.5455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = keras.models.load_model(\n",
        "    \"convnet_from_scratch_with_augmentation3.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ua0-mGXU2CWh",
        "outputId": "1b3a8924-b7f7-476c-b646-6982ad21931f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 2s 36ms/step - loss: 0.6742 - accuracy: 0.5790\n",
            "Test accuracy: 0.579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy=53.7%\n",
        "val_acc=54.5%\n",
        "test_acc=57.9%"
      ],
      "metadata": {
        "id": "uqBaK12ewnWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Using a pre-trained network"
      ],
      "metadata": {
        "id": "iyeiwR1XwndR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16 is the architecture of this pre-trained network."
      ],
      "metadata": {
        "id": "N_Qhf7sdxEDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction - Instantiating the VGG16 convolutional base"
      ],
      "metadata": {
        "id": "C-2gOlMgxZBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(180, 180, 3))\n",
        "conv_base.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nOSdYZVx2FVg",
        "outputId": "26fa6054-3c3c-4e10-a459-b3fcb997b1cb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 180, 180, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 180, 180, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 90, 90, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 90, 90, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 90, 90, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 45, 45, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 45, 45, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 45, 45, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 22, 22, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 22, 22, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction - Extracting features and corresponding labels"
      ],
      "metadata": {
        "id": "a2A58RX2xf0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "def get_features_and_labels(dataset):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    for images, labels in dataset:\n",
        "        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
        "        features = conv_base.predict(preprocessed_images)\n",
        "        all_features.append(features)\n",
        "        all_labels.append(labels)\n",
        "    return np.concatenate(all_features), np.concatenate(all_labels)\n",
        "\n",
        "train_features, train_labels =  get_features_and_labels(train_dataset)\n",
        "val_features, val_labels =  get_features_and_labels(validation_dataset)\n",
        "test_features, test_labels =  get_features_and_labels(test_dataset)\n",
        "\n",
        "train_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ROPn5TAH2QG_",
        "outputId": "7a68f2ae-7646-4cf5-9f1f-5f8187b58c4f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 1s 835ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 5, 5, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction - Defining and training the densely connected classifier"
      ],
      "metadata": {
        "id": "FV_ombIwxtrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(5, 5, 512))\n",
        "x = layers.Flatten()(inputs)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "      filepath=\"feature_extractionPT1.keras\",\n",
        "      save_best_only=True,\n",
        "      monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    epochs=15,\n",
        "    validation_data=(val_features, val_labels),\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KzZRjD2V2UU3",
        "outputId": "85755e6b-8f31-422b-cfde-bb7c8074eb02"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "94/94 [==============================] - 2s 11ms/step - loss: 11.9398 - accuracy: 0.9327 - val_loss: 7.4551 - val_accuracy: 0.9600\n",
            "Epoch 2/15\n",
            "94/94 [==============================] - 1s 8ms/step - loss: 3.9196 - accuracy: 0.9767 - val_loss: 4.9980 - val_accuracy: 0.9755\n",
            "Epoch 3/15\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 1.5954 - accuracy: 0.9853 - val_loss: 5.7114 - val_accuracy: 0.9680\n",
            "Epoch 4/15\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 1.2854 - accuracy: 0.9917 - val_loss: 4.4797 - val_accuracy: 0.9770\n",
            "Epoch 5/15\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 1.0241 - accuracy: 0.9927 - val_loss: 5.5629 - val_accuracy: 0.9730\n",
            "Epoch 6/15\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.6034 - accuracy: 0.9947 - val_loss: 5.5550 - val_accuracy: 0.9745\n",
            "Epoch 7/15\n",
            "94/94 [==============================] - 1s 7ms/step - loss: 0.6773 - accuracy: 0.9947 - val_loss: 8.6317 - val_accuracy: 0.9610\n",
            "Epoch 8/15\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.2499 - accuracy: 0.9977 - val_loss: 6.1599 - val_accuracy: 0.9675\n",
            "Epoch 9/15\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.5996 - accuracy: 0.9957 - val_loss: 9.4336 - val_accuracy: 0.9675\n",
            "Epoch 10/15\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.3390 - accuracy: 0.9970 - val_loss: 5.5127 - val_accuracy: 0.9730\n",
            "Epoch 11/15\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.3684 - accuracy: 0.9980 - val_loss: 5.5893 - val_accuracy: 0.9760\n",
            "Epoch 12/15\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.1666 - accuracy: 0.9980 - val_loss: 6.7802 - val_accuracy: 0.9705\n",
            "Epoch 13/15\n",
            "94/94 [==============================] - 1s 6ms/step - loss: 0.1187 - accuracy: 0.9967 - val_loss: 6.4342 - val_accuracy: 0.9735\n",
            "Epoch 14/15\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.0243 - accuracy: 0.9993 - val_loss: 7.0704 - val_accuracy: 0.9750\n",
            "Epoch 15/15\n",
            "94/94 [==============================] - 1s 5ms/step - loss: 0.3254 - accuracy: 0.9983 - val_loss: 6.7969 - val_accuracy: 0.9730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy=99.8%\n",
        "val_acc=97.3%"
      ],
      "metadata": {
        "id": "CiKYKvf_x3k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "6x0a71Tc2Yv9",
        "outputId": "b995c37c-d256-45df-d94f-77ee112c3d78"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base  = keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False)\n",
        "conv_base.trainable = False\n",
        "     \n",
        "\n",
        "conv_base.trainable = True\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"before freezing the conv base:\", len(conv_base.trainable_weights))\n",
        "     \n",
        "\n",
        "conv_base.trainable = False\n",
        "print(\"This is the number of trainable weights \"\n",
        "      \"after freezing the conv base:\", len(conv_base.trainable_weights))\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9iF5RStd2gGW",
        "outputId": "58336849-3358-46ce-ef8f-34170944b57f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 26\n",
            "This is the number of trainable weights after freezing the conv base: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature extraction with Data Augmentation"
      ],
      "metadata": {
        "id": "iftbSfQtyDCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = keras.applications.vgg16.preprocess_input(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mUs-D-zN2kmb",
        "outputId": "6c1431e5-e486-4280-f64b-2e65a0c23a59"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"feature_extraction_with_data_augmentationPT2.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=5,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-qIvOhpp2nn9",
        "outputId": "81c25dcc-80af-40b3-84b2-7e1e7ce75670"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 36s 340ms/step - loss: 13.6246 - accuracy: 0.9113 - val_loss: 3.6283 - val_accuracy: 0.9715\n",
            "Epoch 2/5\n",
            "94/94 [==============================] - 27s 282ms/step - loss: 5.6995 - accuracy: 0.9513 - val_loss: 7.6499 - val_accuracy: 0.9650\n",
            "Epoch 3/5\n",
            "94/94 [==============================] - 28s 294ms/step - loss: 4.6745 - accuracy: 0.9603 - val_loss: 4.1293 - val_accuracy: 0.9740\n",
            "Epoch 4/5\n",
            "94/94 [==============================] - 28s 291ms/step - loss: 4.9630 - accuracy: 0.9623 - val_loss: 3.8100 - val_accuracy: 0.9745\n",
            "Epoch 5/5\n",
            "94/94 [==============================] - 27s 288ms/step - loss: 3.4162 - accuracy: 0.9690 - val_loss: 3.3257 - val_accuracy: 0.9740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_model = keras.models.load_model(\n",
        "    \"feature_extraction_with_data_augmentationPT2.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "67upd5DM2pxB",
        "outputId": "12aa5ec5-e75a-4d2e-91c3-c9f793434237"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 3s 87ms/step - loss: 4.3960 - accuracy: 0.9740\n",
            "Test accuracy: 0.974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy=96.9%\n",
        "val_Acc=97.4%\n",
        "test_acc=97.4%"
      ],
      "metadata": {
        "id": "fyOw5nffyHTE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cEF2wAgt2sXr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}